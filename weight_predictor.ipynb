{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meta.py\n",
    "\n",
    "\n",
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        #channel2 = 16\n",
    "\n",
    "        #channel1 = 16\n",
    "        channel1 = 32\n",
    "        channel2 = 16\n",
    "        maxPool2 = 2\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=channel1,\n",
    "                kernel_size=7,\n",
    "                stride=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        #self.conv2 = nn.Sequential(\n",
    "        #    nn.Conv2d(channel1, channel2, 7, 1),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.MaxPool2d(maxPool2),\n",
    "        #)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(channel1, channel2, 7, 1),\n",
    "            nn.Tanh(),\n",
    "            nn.MaxPool2d(maxPool2),\n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        #self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "        #self.out = nn.Linear(channel2 * 8 * 8, 1)\n",
    "        #self.out = nn.Linear(channel2 * 7 * 7, 1)\n",
    "        self.out = nn.Linear(channel2 * 5 * 5, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization\n",
    "class returnVector(nn.Module):\n",
    "    def __init__(self, N):\n",
    "        super(returnVector, self).__init__()\n",
    "\n",
    "        channel2 = 16\n",
    "\n",
    "        self.Weights = torch.nn.Parameter(torch.rand(N) - 0.5)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        return self.Weights\n",
    "class linearOutput(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linearOutput, self).__init__()\n",
    "\n",
    "        channel2 = 16\n",
    "\n",
    "        # self.out = nn.Linear( (channel2 * 5 * 5) + 3 , 1)\n",
    "        self.out1 = nn.Linear(400, 8)\n",
    "        self.out = nn.Linear( 8 , 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.out1(x)\n",
    "        return self.out(x), ''\n",
    "class weightModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(weightModel, self).__init__()\n",
    "\n",
    "        channel2 = 16\n",
    "\n",
    "        #self.lin1 = nn.Linear( (channel2 * 5 * 5) + 1 , 3)\n",
    "        self.lin1 = nn.Linear( 2 , 20)\n",
    "\n",
    "        self.lin2 = nn.Linear( 20  , 1)\n",
    "        # self.lin1 = nn.Linear(2, 5)\n",
    "        # self.lin2 = nn.Linear(5, 5)\n",
    "        # # self.lin3 = nn.Linear(10, 10)\n",
    "        # self.lin4 = nn.Linear(5, 5)\n",
    "        # self.lin5 = nn.Linear(5, 1)\n",
    "\n",
    "        # self.dropout = nn.Dropout(p=0.4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = torch.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        x = self.lin2(x)\n",
    "        # x = torch.relu(x)\n",
    "        # # x = self.lin3(x)\n",
    "        # # x = torch.relu(x)\n",
    "        # # x = self.dropout(x)\n",
    "        # x = self.lin4(x)\n",
    "        # x = torch.relu(x)\n",
    "        # x = self.lin5(x)\n",
    "\n",
    "        return x, ''\n",
    "\n",
    "# model = weightModel()\n",
    "# model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "# params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "# print(params)    \n",
    "\n",
    "def loadnpz(name, allow_pickle=False):\n",
    "    if allow_pickle:\n",
    "        data = np.load(name, allow_pickle=True)\n",
    "    else:\n",
    "        data = np.load(name)\n",
    "    data = data.f.arr_0\n",
    "    return data\n",
    "def doDownSample(image, downSize):\n",
    "\n",
    "    size1 = image.shape[0] // downSize\n",
    "    image = image[:(size1*downSize), :(size1*downSize)]\n",
    "\n",
    "    image = image.reshape((image.shape[0] // downSize, downSize, image.shape[1] // downSize, downSize, 3))\n",
    "    image = np.sum(image, axis=(1, 3))\n",
    "    image = image // (downSize **  2)\n",
    "\n",
    "    return image\n",
    "def downSampler():\n",
    "\n",
    "    folder1 = './Age/crop_part1/'\n",
    "    fNames = os.listdir(folder1)\n",
    "\n",
    "    downSize = 5\n",
    "\n",
    "    allImages = np.zeros((len(fNames), 200 // downSize, 200 // downSize, 3), dtype=int)\n",
    "    ageList = np.zeros(len(fNames), dtype=int)\n",
    "\n",
    "    for a in range(len(fNames)):\n",
    "\n",
    "        print (a)\n",
    "        fname = fNames[a]\n",
    "\n",
    "        age1 = int(fname.split('_')[0])\n",
    "\n",
    "        ageList[a] = age1\n",
    "\n",
    "\n",
    "        image2 = image.imread(folder1 + fname)\n",
    "\n",
    "\n",
    "        image2 = doDownSample(image2, downSize)\n",
    "\n",
    "        allImages[a] = np.copy(image2)\n",
    "\n",
    "    np.savez_compressed('./Age/data/allImages.npz', allImages)\n",
    "    np.savez_compressed('./Age/data/allAges.npz', ageList)\n",
    "def calculateGradVector(model, sizeTotal):\n",
    "\n",
    "    count1 = 0\n",
    "    gradNow = np.zeros((sizeTotal,))\n",
    "    for param in model.parameters():\n",
    "        size1 = param.nelement()\n",
    "        grad1 = param.grad\n",
    "        #print (grad1)\n",
    "        grad1 = grad1.data.numpy()\n",
    "        grad1 = grad1.reshape((size1,))\n",
    "\n",
    "        gradNow[count1:count1+size1] = np.copy(grad1)\n",
    "        count1 += size1\n",
    "\n",
    "    return gradNow\n",
    "def findDataGrad(X, Y, model, optimizer, sizeTotal):\n",
    "\n",
    "    dataGrad = np.zeros((X.shape[0],  sizeTotal))\n",
    "\n",
    "    for a in range(X.shape[0]):\n",
    "        pred1, _ = model(X[a:a+1])\n",
    "\n",
    "        loss1 = (pred1[0, 0] - Y[a]) ** 2\n",
    "        loss1.backward()\n",
    "\n",
    "        gradNow = calculateGradVector(model, sizeTotal)\n",
    "        dataGrad[a] = np.copy(gradNow)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return dataGrad\n",
    "def trainModel(cv = 0):\n",
    "\n",
    "    useMeta = False\n",
    "\n",
    "\n",
    "    X = loadnpz('./Age/data/allImages.npz')\n",
    "    Y = loadnpz('./Age/data/allAges.npz')\n",
    "\n",
    "    #print (X.shape)\n",
    "    #quit()\n",
    "\n",
    "    #plt.hist(Y, bins=100)\n",
    "    #plt.show()\n",
    "    #quit()\n",
    "\n",
    "    Y = Y / 100\n",
    "    X = np.swapaxes(X, 1, 3)\n",
    "    X = np.swapaxes(X, 2, 3)\n",
    "\n",
    "    minAge_test = 0.14\n",
    "    maxAge_test = 0.21\n",
    "\n",
    "    #minAge_valid = 0.12\n",
    "    #maxAge_valid = 0.23\n",
    "    minAge_valid = 0.14\n",
    "    maxAge_valid = 0.21\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    N = Y.shape[0]\n",
    "    rng = np.random.RandomState(0)\n",
    "    perm1 = rng.permutation(N)\n",
    "    X = X[perm1]\n",
    "    Y = Y[perm1]\n",
    "\n",
    "    N_test = 1000\n",
    "    # X_test = X[:N_test]\n",
    "    # Y_test = Y[:N_test]\n",
    "    X_test = X[N_test*cv:N_test*cv+N_test]\n",
    "    Y_test = Y[N_test*cv:N_test*cv+N_test]\n",
    "    X = np.concatenate((X[:N_test*cv], X[N_test*cv + N_test:]), axis=0) \n",
    "    Y = np.concatenate((Y[:N_test*cv], Y[N_test*cv + N_test:]), axis=0) \n",
    "    # X = X[N_test:]\n",
    "    # Y = Y[N_test:]\n",
    "    if useMeta:\n",
    "        N_valid = 1000\n",
    "        X_valid = X[:N_valid]\n",
    "        Y_valid = Y[:N_valid]\n",
    "        X = X[N_valid:]\n",
    "        Y = Y[N_valid:]\n",
    "\n",
    "\n",
    "        validArg = np.argwhere(np.logical_and(Y_valid >= minAge_valid, Y_valid <= maxAge_valid))[:, 0]\n",
    "        X_valid = X_valid[validArg]\n",
    "        Y_valid = Y_valid[validArg]\n",
    "\n",
    "        X_valid = torch.tensor(X_valid).float()\n",
    "        Y_valid = torch.tensor(Y_valid).float()\n",
    "\n",
    "\n",
    "    X = torch.tensor(X).float()\n",
    "    Y = torch.tensor(Y).float()\n",
    "    X_test = torch.tensor(X_test).float()\n",
    "    Y_test = torch.tensor(Y_test).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    metaTest = False\n",
    "\n",
    "    if metaTest:\n",
    "        testArg = np.argwhere(np.logical_and(Y_test.data.numpy() >= minAge_test, Y_test.data.numpy() <= maxAge_test))[:, 0]\n",
    "        X_test = X_test[testArg]\n",
    "        Y_test = Y_test[testArg]\n",
    "\n",
    "\n",
    "    restrictTrain = False\n",
    "    if restrictTrain:\n",
    "        trainArg = np.argwhere(np.logical_and(Y.data.numpy() >= minAge_test, Y.data.numpy() <= maxAge_test))[:, 0]\n",
    "        X = X[trainArg]\n",
    "        Y = Y[trainArg]\n",
    "\n",
    "    #print (X.shape)\n",
    "    #quit()\n",
    "\n",
    "\n",
    "    N_train = Y.shape[0]\n",
    "\n",
    "\n",
    "    #model = torch.load('./models/2.pt')\n",
    "    model = CNN().to('cuda')\n",
    "\n",
    "\n",
    "    sizeTotal = 0\n",
    "    for param in model.parameters():\n",
    "        size1 = param.nelement()\n",
    "        sizeTotal += size1\n",
    "\n",
    "\n",
    "\n",
    "    #learningRate = 1e-3\n",
    "    #learningRate = 5e-4\n",
    "    #learningRate = 3e-4\n",
    "    learningRate = 1e-4\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = learningRate)\n",
    "\n",
    "\n",
    "    iterN = 100\n",
    "    batchSize = 100\n",
    "    Nbatch = N_train // batchSize\n",
    "\n",
    "    trainLoss = []\n",
    "\n",
    "    for iter in range(iterN):\n",
    "\n",
    "        for batchNum in range(Nbatch):\n",
    "\n",
    "            X_batch = X[batchNum*batchSize:(batchNum+1)*batchSize].to('cuda')\n",
    "            Y_batch = Y[batchNum*batchSize:(batchNum+1)*batchSize].to('cuda')\n",
    "\n",
    "            if useMeta:\n",
    "                dataGrad = findDataGrad(X_batch, Y_batch, model, optimizer, sizeTotal)\n",
    "\n",
    "\n",
    "                pred_valid, _ = model(X_valid)\n",
    "                pred_valid = pred_valid[:, 0]\n",
    "                loss_Valid = torch.mean((pred_valid - Y_valid) ** 2)\n",
    "                loss_Valid.backward()\n",
    "\n",
    "                validGrad = calculateGradVector(model, sizeTotal)\n",
    "                validDir = validGrad\n",
    "                validDir = validDir.reshape((1, validDir.shape[0]))\n",
    "\n",
    "                dataValue = np.sum(validDir * dataGrad, axis=1)\n",
    "\n",
    "                #norm1 = np.sum(validDir**2, axis=1) ** 0.5\n",
    "                #norm2 = np.sum(dataGrad**2, axis=1) ** 0.5\n",
    "                #dataValue = dataValue / (norm1 * norm2)\n",
    "\n",
    "                #plt.scatter(Y_batch.data.numpy(), dataValue)\n",
    "                #plt.show()\n",
    "                #quit()\n",
    "\n",
    "                #weighting = np.zeros(dataValue.shape[0])\n",
    "                #weighting[dataValue > 0] = 1\n",
    "\n",
    "                weighting = np.copy(dataValue) / 2\n",
    "                weighting[weighting<0] = 0\n",
    "                weighting[weighting>1] = 1\n",
    "\n",
    "                #print (torch.mean(Y_batch[dataValue > 0]), torch.mean(Y_batch))\n",
    "\n",
    "\n",
    "\n",
    "                weighting = torch.tensor(weighting).float()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            pred, _ = model(X_batch)\n",
    "            pred = pred[:, 0]\n",
    "            loss = (pred - Y_batch) ** 2\n",
    "\n",
    "            if useMeta:\n",
    "                loss = loss * weighting\n",
    "\n",
    "            loss = torch.mean(loss)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        #print ('range')\n",
    "        #print (np.quantile(Y_batch[dataValue > 0].data.numpy(), np.array([0.25, 0.75])))\n",
    "        #print (np.quantile(Y_batch.data.numpy(), np.array([0.25, 0.75])))\n",
    "\n",
    "\n",
    "        pred_test, _ = model(X_test.to('cuda'))\n",
    "        pred_test = pred_test[:, 0]\n",
    "\n",
    "        cor_test = scipy.stats.pearsonr(pred_test.to('cpu').data.numpy(), Y_test.data.numpy())\n",
    "\n",
    "        if useMeta:\n",
    "            pred_valid, _ = model(X_valid.to('cuda'))\n",
    "            pred_valid = pred_valid[:, 0]\n",
    "\n",
    "            #print (pred_valid.shape, Y_valid.shape)\n",
    "            cor_valid = scipy.stats.pearsonr(pred_valid.to('cpu').data.numpy(), Y_valid.data.numpy())\n",
    "\n",
    "        pred_train, _ = model(X[:N_test].to('cuda'))\n",
    "        pred_train = pred_train[:, 0]\n",
    "\n",
    "        cor_train = scipy.stats.pearsonr(pred_train.to('cpu').data.numpy(), Y[:N_test].data.numpy())\n",
    "\n",
    "        lossInfo = [cor_train[0], cor_test[0]]\n",
    "\n",
    "        #print (\"Scores\")\n",
    "        print ('iter', iter)\n",
    "        print (cor_train)\n",
    "        if useMeta:\n",
    "            print (cor_valid)\n",
    "            lossInfo = [cor_train[0], cor_valid[0], cor_test[0]]\n",
    "        print (cor_test)\n",
    "\n",
    "        trainLoss.append(copy.copy(lossInfo))\n",
    "\n",
    "        #np.save('./results/trainLoss_someData.npy', np.array(trainLoss))\n",
    "        #torch.save(model, './models/1_someData.pt')\n",
    "\n",
    "        torch.save({'state_dict': model.state_dict()}, './models/cv_'+str(cv)+'pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(W):\n",
    "    return 1/(torch.abs(W)**2 + 1)\n",
    "    # return 1+torch.tanh(W)\n",
    "def target_func_np(W):\n",
    "    return 1/(np.abs(W)**2 + 1)\n",
    "    # return 1 + np.tanh(W)\n",
    "\n",
    "def trainWeightingLinear(useMeta = True, restrictTrain = False, iterN = 1000, vcv = 0, cv=0, wmodel=None):\n",
    "\n",
    "    # useMeta = False\n",
    "\n",
    "    # Load in Data + Preprocessing\n",
    "    X = loadnpz('./Age/data/allImages.npz')\n",
    "    Y = loadnpz('./Age/data/allAges.npz')\n",
    "\n",
    "    Y = Y / 100\n",
    "    X = np.swapaxes(X, 1, 3)\n",
    "    X = np.swapaxes(X, 2, 3)\n",
    "\n",
    "    minAge_test = 0.14\n",
    "    maxAge_test = 0.21\n",
    "\n",
    "    minAge_valid = 0.14\n",
    "    maxAge_valid = 0.21\n",
    "\n",
    "    featureModel = CNN()\n",
    "    checkpoint = torch.load('models/cv_'+str(cv)+'.pt')\n",
    "    featureModel.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    # featureModel = torch.load('./models/3.pt')\n",
    "\n",
    "    N = Y.shape[0]\n",
    "    rng = np.random.RandomState(0)\n",
    "    #rng = np.random.RandomState(1)\n",
    "    #rng = np.random.RandomState(2)\n",
    "    perm1 = rng.permutation(N)\n",
    "    X = X[perm1]\n",
    "    Y = Y[perm1]\n",
    "\n",
    "\n",
    "    X = torch.tensor(X).float()\n",
    "    originalPred, X = featureModel(X)\n",
    "    X = X.data.numpy()\n",
    "    onesAdd = np.ones((X.shape[0], 1), dtype=float)\n",
    "    X = np.concatenate((X,onesAdd), axis=1)\n",
    "\n",
    "    originalPred = originalPred.data.numpy()\n",
    "    originalPred = torch.tensor(originalPred).float()\n",
    "\n",
    "    N_test = 1000\n",
    "    X_test = X[N_test*cv:N_test*cv+N_test]\n",
    "    Y_test = Y[N_test*cv:N_test*cv+N_test]\n",
    "    X = np.concatenate((X[:N_test*cv], X[N_test*cv + N_test:]), axis=0) \n",
    "    Y = np.concatenate((Y[:N_test*cv], Y[N_test*cv + N_test:]), axis=0)\n",
    "    # X_test = X[:N_test]\n",
    "    # Y_test = Y[:N_test]\n",
    "    originalPred = torch.cat((originalPred[:N_test*cv], originalPred[N_test*cv + N_test:]), axis=0) \n",
    "    # X = X[N_test:]\n",
    "    # Y = Y[N_test:]\n",
    "    originalPred_test = originalPred[N_test*cv:N_test*cv+N_test]\n",
    "    # print(originalPred.shape)\n",
    "    \n",
    "    \n",
    "    if useMeta:\n",
    "        # BUILD CROSS VALIDATION HERE\n",
    "        N_valid = 1000\n",
    "        X_valid = X[N_valid*vcv:N_valid*vcv+N_valid]\n",
    "        Y_valid = Y[N_valid*vcv:N_valid*vcv+N_valid]\n",
    "        originalPred_valid = originalPred[N_valid*vcv:N_valid*vcv+N_valid]\n",
    "        X = np.concatenate((X[:N_valid*vcv], X[N_valid*vcv + N_valid:]), axis=0) \n",
    "        Y = np.concatenate((Y[:N_valid*vcv], Y[N_valid*vcv + N_valid:]), axis=0) \n",
    "        originalPred = torch.cat((originalPred[:N_valid*vcv], originalPred[N_valid*vcv + N_valid:]), axis=0) \n",
    "\n",
    "\n",
    "        validArg = np.argwhere(np.logical_and(Y_valid >= minAge_valid, Y_valid <= maxAge_valid))[:, 0]\n",
    "        X_valid = X_valid[validArg]\n",
    "        Y_valid = Y_valid[validArg]\n",
    "        originalPred_valid = originalPred_valid[validArg]\n",
    "\n",
    "        X_valid = torch.tensor(X_valid).float()\n",
    "        Y_valid = torch.tensor(Y_valid).float()\n",
    "        \n",
    "        \n",
    "\n",
    "    X = torch.tensor(X).float()\n",
    "    Y = torch.tensor(Y).float()\n",
    "    X_test = torch.tensor(X_test).float()\n",
    "    Y_test = torch.tensor(Y_test).float()\n",
    "\n",
    "\n",
    "    metaTest = True\n",
    "\n",
    "    if metaTest:\n",
    "        testArg = np.argwhere(np.logical_and(Y_test.data.numpy() >= minAge_test, Y_test.data.numpy() <= maxAge_test))[:, 0]\n",
    "        X_test = X_test[testArg]\n",
    "        Y_test = Y_test[testArg]\n",
    "        originalPred_test = originalPred_test[testArg]\n",
    "\n",
    "\n",
    "    \n",
    "    if restrictTrain:\n",
    "        #trainArg = np.argwhere(np.logical_and(Y.data.numpy() >= minAge_valid, Y.data.numpy() <= maxAge_valid))[:, 0]\n",
    "        trainArg = np.argwhere(np.logical_and(Y.data.numpy() >= minAge_test, Y.data.numpy() <= maxAge_test))[:, 0]\n",
    "        X = X[trainArg]\n",
    "        Y = Y[trainArg]\n",
    "        originalPred = originalPred[trainArg]\n",
    "\n",
    "    N_train = Y.shape[0]\n",
    "\n",
    "    predModel = weightModel()\n",
    "\n",
    "\n",
    "    learningRate = 5e-3\n",
    "    optimizer = torch.optim.Adam(predModel.parameters(), lr = learningRate)\n",
    "\n",
    "    #learningRate = 1e-3\n",
    "    #learningRate = 1e-4\n",
    "    #optimizer = torch.optim.RMSprop(predModel.parameters(), lr = learningRate)\n",
    "\n",
    "    #learningRate = 1e-1\n",
    "    #optimizer = torch.optim.SGD(predModel.parameters(), lr = learningRate)\n",
    "\n",
    "\n",
    "    # iterN = 1000\n",
    "    batchSize = 100\n",
    "    Nbatch = N_train // batchSize\n",
    "\n",
    "    testloss = []\n",
    "    testcorr = []\n",
    "    best_err = 10000\n",
    "    best_model = None\n",
    "\n",
    "    if useMeta or wmodel != None:\n",
    "        X_both = torch.cat(( (Y-0.18).reshape((-1, 1)) , (originalPred-0.18) ), axis=1) * 5\n",
    "        # plt.scatter(100*(X_both[:, 0]/5 + 0.18), 100*(X_both[:, 1]/5 + 0.18))\n",
    "        # plt.show()\n",
    "\n",
    "    for iter in range(iterN):\n",
    "        if useMeta:\n",
    "            #W = predModel()\n",
    "            #W = (torch.tanh(W) + 1) / 1\n",
    "            #W = W.reshape((W.shape[0], 1))\n",
    "\n",
    "            #W, _ = predModel(X[:, :-1])\n",
    "            #W = (torch.tanh(W) + 1) / 1\n",
    "\n",
    "            #X_both = torch.cat((X[:, :-1], Y.reshape((-1, 1)) * 10  ), axis=1)\n",
    "\n",
    "\n",
    "\n",
    "            #X_both = torch.cat((X[:, :-1] * 0, (Y-0.18).reshape((-1, 1)) , torch.abs(Y-0.18).reshape((-1, 1)) , ((Y-0.18)**2).reshape((-1, 1))  ), axis=1)\n",
    "            #X_both = torch.cat(( (Y-0.18).reshape((-1, 1)) , torch.abs(Y-0.18).reshape((-1, 1)) , ((Y-0.18)**2).reshape((-1, 1)) , (originalPred-0.18), torch.abs(originalPred-0.18) , (originalPred-0.18) ** 2, torch.abs(Y.reshape((-1, 1)) - originalPred), (Y.reshape((-1, 1)) - originalPred)**2  ), axis=1)\n",
    "            \n",
    "            W, _ = predModel(X_both)\n",
    "            # W =  1 / torch.log( torch.exp(-1 * W) + np.exp(1.0) )\n",
    "            # W = 1 + torch.tanh(W)\n",
    "            W = target_func(W)\n",
    "            if(iter%10 == 0):\n",
    "                print(W.shape, torch.argwhere(W > 0.1).shape)\n",
    "\n",
    "        elif wmodel != None:\n",
    "            # X_both = torch.cat(( (Y-0.18).reshape((-1, 1)) , (originalPred-0.18) ), axis=1) * 5\n",
    "            W, _ = wmodel(X_both)\n",
    "            # W = (torch.tanh(W) + 1) / 1\n",
    "            W = target_func(W)\n",
    "            print(\"using pretrained weights\")\n",
    "            \n",
    "        else:\n",
    "            W = torch.ones((X.shape[0], 1))\n",
    "\n",
    "        XW = (W * X).T\n",
    "\n",
    "        XX_mat = torch.matmul(XW, X)\n",
    "\n",
    "        #print (XX_mat)\n",
    "        #print ((1e-1 * X.shape[0]))\n",
    "        #quit()\n",
    "\n",
    "        ridgeReg = 5e-3\n",
    "        #ridgeReg = 1e-2\n",
    "        # ridgeReg = 2e-2\n",
    "        #ridgeReg = 1e-1\n",
    "\n",
    "        XX_mat_inv = torch.inverse(XX_mat + (ridgeReg * X.shape[0] * torch.eye(XX_mat.shape[0]))  )\n",
    "        XY_mat = torch.matmul(XW, Y)\n",
    "\n",
    "        weightBeta = torch.matmul(XX_mat_inv, XY_mat)\n",
    "\n",
    "        weightBeta = weightBeta.reshape((-1, 1))\n",
    "\n",
    "\n",
    "        pred_train = torch.matmul(X, weightBeta)\n",
    "        pred_train = pred_train[:, 0]\n",
    "\n",
    "        #print (np.mean(Y.data.numpy()))\n",
    "        #print (np.mean(pred_train.data.numpy()))\n",
    "        #print (np.mean(   (pred_train.data.numpy() -  Y.data.numpy())  **2 ))\n",
    "        #quit()\n",
    "\n",
    "        # cor_train = scipy.stats.pearsonr(pred_train.data.numpy(), Y.data.numpy())\n",
    "\n",
    "\n",
    "        pred_test = torch.matmul(X_test, weightBeta)\n",
    "        pred_test = pred_test[:, 0]\n",
    "        cor_test = scipy.stats.pearsonr(pred_test.data.numpy(), Y_test.data.numpy())\n",
    "\n",
    "        if useMeta:\n",
    "            pred_valid = torch.matmul(X_valid, weightBeta)\n",
    "            pred_valid = pred_valid[:, 0]\n",
    "            # cor_valid = scipy.stats.pearsonr(pred_valid.data.numpy(), Y_valid.data.numpy())\n",
    "        \n",
    "        \n",
    "        testloss.append(torch.mean((pred_test - Y_test) ** 2).data.numpy())\n",
    "        \n",
    "        if(testloss[-1] < best_err):\n",
    "            best_err = testloss[-1]\n",
    "            best_model = predModel\n",
    "\n",
    "\n",
    "        if(iter % 20 == 0):\n",
    "            print (iter)\n",
    "            # print (cor_train)\n",
    "\n",
    "            # if useMeta:\n",
    "                # print (cor_valid)\n",
    "            # print (cor_test, testloss[-1])\n",
    "            print('test', testloss[-1])\n",
    "            if(useMeta):\n",
    "                print('valid', torch.mean((pred_valid - Y_valid) ** 2).data.numpy())\n",
    "        testcorr.append(cor_test)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        if not useMeta:\n",
    "            acc = 0\n",
    "            return acc, torch.mean((pred_test - Y_test) ** 2).data.numpy()\n",
    "\n",
    "        if useMeta:\n",
    "\n",
    "            loss = torch.mean(  (pred_valid - Y_valid) ** 2)\n",
    "            # loss = torch.mean(  torch.abs(pred_valid - Y_valid))\n",
    "\n",
    "            #pred_valid = pred_valid - torch.mean(pred_valid) + torch.mean(Y_valid)\n",
    "            #loss = torch.mean(  torch.abs(pred_valid - Y_valid))\n",
    "\n",
    "\n",
    "            #reg = 0\n",
    "            #for param in predModel.parameters():\n",
    "            #    reg += torch.sum(torch.abs(param))\n",
    "\n",
    "            #loss = loss + (2e-5 * reg)\n",
    "            #loss = loss + (1e-4 * reg)\n",
    "            #loss = loss + (1e-3 * reg)\n",
    "            #loss = loss + (1e-2 * reg)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "\n",
    "            torch.nn.utils.clip_grad_value_(predModel.parameters(), 1e-4) #good\n",
    "\n",
    "            #torch.nn.utils.clip_grad_value_(predModel.parameters(), 2e-5)\n",
    "\n",
    "            optimizer.step()\n",
    "        if(iter % 500 == 499):\n",
    "            hm(predModel)\n",
    "            \n",
    "\n",
    "    predModel.eval()\n",
    "    finalCor = trainWeightingLinear(useMeta = False, restrictTrain = False, iterN = 1000, vcv = vcv, cv=cv, wmodel=best_model)\n",
    "    cor_train = 0\n",
    "    cor_valid = 0\n",
    "    return best_model, cor_train, cor_valid, finalCor, testloss, testcorr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hm(model):\n",
    "    heat_map = np.zeros((100, 100))\n",
    "    scaled_heat_map = np.zeros((100, 100))\n",
    "    r = 0\n",
    "    c = 0\n",
    "    # m = torch.load('models/weights.pt')\n",
    "    m = model\n",
    "    with torch.no_grad():\n",
    "        m.eval()\n",
    "        for t in [i/100 for i in range(1, 101)]:\n",
    "            c = 0\n",
    "            for p in [i/100 for i in range(1, 101)]:\n",
    "                inp = torch.Tensor(np.array([5*(t - 0.18), 5*(p-0.18)]))\n",
    "                # print(inp.shape)\n",
    "                heat_map[r, c] = m(inp)[0].item()\n",
    "                # scaled_heat_map[r, c] =1/(np.exp(heat_map[r, c] * -1) +1 )\n",
    "                # scaled_heat_map[r, c] = np.tanh(heat_map[r, c]) + 1\n",
    "                scaled_heat_map[r, c] = target_func_np(heat_map[r, c])\n",
    "                # print(t, p, heat_map[r, c])\n",
    "                c+=1\n",
    "            r+=1\n",
    "\n",
    "    plt.imshow(scaled_heat_map, extent=[1, 100, 100, 1])\n",
    "    plt.colorbar()\n",
    "    plt.xlabel('predicted age')\n",
    "    plt.ylabel('actual age')\n",
    "    plt.title('Data Reweighting')\n",
    "    plt.show()\n",
    "    # plt.imshow(heat_map, extent=[14, 100, 100, 14])\n",
    "    # plt.colorbar()\n",
    "    # plt.xlabel('predicted age')\n",
    "    # plt.ylabel('actual age')\n",
    "    # plt.title('Data Reweighting (logits)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     trainModel(cv=i)\n",
    "\n",
    "# trainModel(cv=4)\n",
    "# trainModel(cv=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "all_err = []\n",
    "rest = []\n",
    "rest_err = []\n",
    "tr = []\n",
    "tr_err = []\n",
    "va = []\n",
    "te = []\n",
    "trl = []\n",
    "trc = []\n",
    "# fr = []\n",
    "models = []\n",
    "for cv in range(8):\n",
    "    print('=======================', cv, '======================')\n",
    "    corr_all, loss_all = trainWeightingLinear(useMeta = False, restrictTrain=False, cv = cv)\n",
    "    # all.append(corr_all[0])\n",
    "    all_err.append(loss_all)\n",
    "    # trainWeightingLinear(iterN = 600, cv=cv)\n",
    "    corr_restrict, loss_restrict = trainWeightingLinear(useMeta = False, restrictTrain=True, cv = cv)\n",
    "    # rest.append(corr_restrict[0])\n",
    "    rest_err.append(loss_restrict)\n",
    "\n",
    "    model, t, v, tt, trloss, trcorr = trainWeightingLinear(iterN = 2000, cv=cv, vcv = 2)\n",
    "    # tr.append(t)\n",
    "    # va.append(v)\n",
    "    te.append(tt)\n",
    "    trl.append(trloss)\n",
    "    # trc.append(trcorr)\n",
    "    models.append(model)\n",
    "    # fr.append(fres)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for p in trl:\n",
    "    s = [x for x in p]\n",
    "    plt.plot(s, label=str(i))\n",
    "    plt.scatter([990, 790], [all_err[i], rest_err[i]], label=str(i))\n",
    "    # plt.scatter([4890], rest[i], label = str(i))\n",
    "    i+=1\n",
    "# plt.scatter([4990]*len(trl), all)\n",
    "# plt.scatter([4950]*len(trl), rest)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "m = np.mean(np.array(trl), axis=0)\n",
    "s = np.std(np.array(trl), axis=0)\n",
    "r = 100\n",
    "\n",
    "tet = [x[0] for x in te]\n",
    "print(tet)\n",
    "\n",
    "plt.errorbar(r*np.arange(m[::r].shape[0]), m[::r], yerr=s[::r], label='ours')\n",
    "plt.errorbar([990], np.mean(all_err), yerr = np.std(all_err), label='all')\n",
    "plt.errorbar([990], np.mean(rest_err), yerr = np.std(rest_err), label='restricted')\n",
    "plt.errorbar([1500], np.mean(tet), yerr = np.std(tet), label='ourfinal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print(m[-1], np.mean(all_err), np.mean(rest_err))\n",
    "\n",
    "true_res = []\n",
    "max_res = []\n",
    "for idx, model in enumerate(models):\n",
    "    s = [x for x in trl[idx]]\n",
    "    print(s[-1], all_err[idx], rest_err[idx], idx)\n",
    "    max_res.append(np.max(s))\n",
    "    model.eval()\n",
    "    acc, err = trainWeightingLinear(useMeta = False, restrictTrain = False, cv=idx, wmodel=model)\n",
    "    true_res.append(err)\n",
    "    # print(acc)\n",
    "    hm(model)\n",
    "\n",
    "print(true_res)\n",
    "print(rest_err)\n",
    "print(all_err)\n",
    "\n",
    "plt.plot(true_res)\n",
    "plt.plot(rest_err)\n",
    "plt.show()\n",
    "print(np.mean(true_res))\n",
    "print(np.mean(max_res))\n",
    "print(np.mean(rest))\n",
    "print(np.mean(all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, t, v, tt, trloss = trainWeightingLinear(iterN = 1000, cv=6, vcv = 2)\n",
    "plt.scatter(np.arange(8), [400*i for i in true_res], label='Ours')\n",
    "plt.scatter(np.arange(8), [400*i for i in rest_err], label='Restricted')\n",
    "plt.legend()\n",
    "plt.xlabel('Test Split')\n",
    "plt.ylabel('Mean Square Error (Years^2)')\n",
    "print()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot([1 - true_res[i]/rest_err[i] for i in range(8)])\n",
    "np.mean([true_res[i]/rest_err[i] for i in range(8)])\n",
    "plt.show()\n",
    "st = [400*i for i in true_res]\n",
    "sr = [400*i for i in rest_err]\n",
    "sa = [400*i for i in all_err]\n",
    "\n",
    "diff = [sr[i] - st[i] for i in range(8)]\n",
    "print(diff)\n",
    "print(np.std(st), np.mean(st))\n",
    "print(np.std(sr), np.mean(sr))\n",
    "print(np.std(sa), np.mean(sa))\n",
    "print(np.std(diff), np.mean(diff))\n",
    "\n",
    "# np.savetxt('ours_scaled.txt', st)\n",
    "# np.savetxt('rest_scaled.txt', sr)\n",
    "# np.savetxt('all_scaled.txt', sa)\n",
    "\n",
    "t = np.loadtxt('ours_scaled.txt')\n",
    "r = np.loadtxt('rest_scaled.txt')\n",
    "a = np.loadtxt('all_scaled.txt')\n",
    "\n",
    "stt = np.concatenate((st, t))\n",
    "srr = np.concatenate((sr, r))\n",
    "saa = np.concatenate((sa, a))\n",
    "\n",
    "plt.scatter(np.arange(16), stt, label='Ours')\n",
    "plt.scatter(np.arange(16), srr, label='Restricted')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "diff2 = [srr[i] - stt[i] for i in range(16)]\n",
    "print(diff)\n",
    "print(np.std(stt), np.mean(stt))\n",
    "print(np.std(srr), np.mean(srr))\n",
    "print(np.std(saa), np.mean(saa))\n",
    "print(np.std(diff2), np.mean(diff2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = [x[0] for x in trloss]\n",
    "ind = 5\n",
    "\n",
    "plt.scatter([4990, 4590], [all[ind], rest[ind]], label=str(ind))\n",
    "plt.plot(s)\n",
    "rep = True\n",
    "if rep:\n",
    "    trl[ind] = trloss\n",
    "    models[ind] = model\n",
    "    tr[ind] = t\n",
    "    va[ind] = v\n",
    "    te[ind] = tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.loadtxt('ours_scaled.txt')\n",
    "r = np.loadtxt('rest_scaled.txt')\n",
    "a = np.loadtxt('all_scaled.txt')\n",
    "plt.scatter(np.arange(8), t, label='Ours')\n",
    "plt.scatter(np.arange(8), r, label='Restricted')\n",
    "plt.xlabel('Train/Test Split Number')\n",
    "plt.ylabel('Mean Squared Error (Years^2)')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "al = []\n",
    "rl = []\n",
    "ml = []\n",
    "for cv in range(8):\n",
    "    print('=======================', cv, '======================')\n",
    "    loss_all = trainWeightingLinear(useMeta = False, restrictTrain=False, cv = cv)\n",
    "    al.append(loss_all[0])\n",
    "    # trainWeightingLinear(iterN = 600, cv=cv)\n",
    "    loss_restrict = trainWeightingLinear(useMeta = False, restrictTrain=True, cv = cv)\n",
    "    rl.append(loss_restrict[0])\n",
    "\n",
    "    loss_model = trainWeightingLinear(useMeta = False, iterN = 2000, cv=cv, vcv = 2, wmodel = models[7])\n",
    "    ml.append(loss_model[0])\n",
    "\n",
    "print(np.mean(al), np.mean(rl), np.mean(ml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7780, 1]) torch.Size([7780, 2])\n",
      "0\n",
      "test 0.01789844\n",
      "valid 0.010555065\n",
      "torch.Size([7780, 1]) torch.Size([7780, 2])\n",
      "torch.Size([7780, 1]) torch.Size([7766, 2])\n",
      "20\n",
      "test 0.012168354\n",
      "valid 0.0073870514\n",
      "torch.Size([7780, 1]) torch.Size([7260, 2])\n",
      "torch.Size([7780, 1]) torch.Size([6355, 2])\n",
      "40\n",
      "test 0.007731425\n",
      "valid 0.00501476\n",
      "torch.Size([7780, 1]) torch.Size([5580, 2])\n",
      "torch.Size([7780, 1]) torch.Size([5068, 2])\n",
      "60\n",
      "test 0.0047797184\n",
      "valid 0.0035030735\n",
      "torch.Size([7780, 1]) torch.Size([4709, 2])\n",
      "torch.Size([7780, 1]) torch.Size([4409, 2])\n",
      "80\n",
      "test 0.003147128\n",
      "valid 0.0025894651\n",
      "torch.Size([7780, 1]) torch.Size([3775, 2])\n",
      "torch.Size([7780, 1]) torch.Size([2216, 2])\n",
      "100\n",
      "test 0.0021208888\n",
      "valid 0.001914877\n",
      "torch.Size([7780, 1]) torch.Size([1731, 2])\n",
      "torch.Size([7780, 1]) torch.Size([1402, 2])\n",
      "120\n",
      "test 0.0014168788\n",
      "valid 0.001387778\n",
      "torch.Size([7780, 1]) torch.Size([1200, 2])\n",
      "torch.Size([7780, 1]) torch.Size([1061, 2])\n",
      "140\n",
      "test 0.00095718756\n",
      "valid 0.0010340975\n",
      "torch.Size([7780, 1]) torch.Size([948, 2])\n",
      "torch.Size([7780, 1]) torch.Size([848, 2])\n",
      "160\n",
      "test 0.0007133685\n",
      "valid 0.00082826393\n",
      "torch.Size([7780, 1]) torch.Size([783, 2])\n",
      "torch.Size([7780, 1]) torch.Size([725, 2])\n",
      "180\n",
      "test 0.00059618056\n",
      "valid 0.0007163581\n",
      "torch.Size([7780, 1]) torch.Size([698, 2])\n",
      "torch.Size([7780, 1]) torch.Size([665, 2])\n",
      "200\n",
      "test 0.00053658034\n",
      "valid 0.00065367477\n",
      "torch.Size([7780, 1]) torch.Size([637, 2])\n",
      "torch.Size([7780, 1]) torch.Size([605, 2])\n",
      "220\n",
      "test 0.00050051004\n",
      "valid 0.00060959085\n",
      "torch.Size([7780, 1]) torch.Size([588, 2])\n",
      "torch.Size([7780, 1]) torch.Size([568, 2])\n",
      "240\n",
      "test 0.00047259784\n",
      "valid 0.0005780222\n",
      "torch.Size([7780, 1]) torch.Size([553, 2])\n",
      "torch.Size([7780, 1]) torch.Size([540, 2])\n",
      "260\n",
      "test 0.00045963682\n",
      "valid 0.0005562874\n",
      "torch.Size([7780, 1]) torch.Size([530, 2])\n",
      "torch.Size([7780, 1]) torch.Size([514, 2])\n",
      "280\n",
      "test 0.00044985843\n",
      "valid 0.0005395506\n",
      "torch.Size([7780, 1]) torch.Size([502, 2])\n",
      "torch.Size([7780, 1]) torch.Size([494, 2])\n",
      "300\n",
      "test 0.0004431098\n",
      "valid 0.000526323\n",
      "torch.Size([7780, 1]) torch.Size([487, 2])\n",
      "torch.Size([7780, 1]) torch.Size([481, 2])\n",
      "320\n",
      "test 0.00043953484\n",
      "valid 0.0005152921\n",
      "torch.Size([7780, 1]) torch.Size([472, 2])\n",
      "torch.Size([7780, 1]) torch.Size([464, 2])\n",
      "340\n",
      "test 0.0004364695\n",
      "valid 0.00050626654\n",
      "torch.Size([7780, 1]) torch.Size([460, 2])\n",
      "torch.Size([7780, 1]) torch.Size([455, 2])\n",
      "360\n",
      "test 0.00043513297\n",
      "valid 0.0004983343\n",
      "torch.Size([7780, 1]) torch.Size([449, 2])\n",
      "torch.Size([7780, 1]) torch.Size([443, 2])\n",
      "380\n",
      "test 0.00043445374\n",
      "valid 0.0004920474\n",
      "torch.Size([7780, 1]) torch.Size([435, 2])\n",
      "torch.Size([7780, 1]) torch.Size([427, 2])\n",
      "400\n",
      "test 0.00043419722\n",
      "valid 0.00048661706\n",
      "torch.Size([7780, 1]) torch.Size([423, 2])\n",
      "torch.Size([7780, 1]) torch.Size([417, 2])\n",
      "420\n",
      "test 0.00043440558\n",
      "valid 0.0004818384\n",
      "torch.Size([7780, 1]) torch.Size([415, 2])\n",
      "torch.Size([7780, 1]) torch.Size([411, 2])\n",
      "440\n",
      "test 0.00043472665\n",
      "valid 0.00047761132\n",
      "torch.Size([7780, 1]) torch.Size([407, 2])\n",
      "torch.Size([7780, 1]) torch.Size([403, 2])\n",
      "460\n",
      "test 0.000435215\n",
      "valid 0.00047390998\n",
      "torch.Size([7780, 1]) torch.Size([400, 2])\n",
      "torch.Size([7780, 1]) torch.Size([397, 2])\n",
      "480\n",
      "test 0.00043579\n",
      "valid 0.00047070396\n",
      "torch.Size([7780, 1]) torch.Size([395, 2])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUIAAAEWCAYAAAATsp59AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA0wklEQVR4nO29eZgkV3Wn/f4icqmstfeW1C2phSSEBFgSiN3IYrVsY8AzWIBhLBhsDZ7xmM0YPJ7BGM/MB2MPGMbAILNpbIwAGYMAgSxAEiBLAm0IJCHQ3qt6q70ql4g43x8R2Z1dXdWVVV1ZmVV53ueJJyNu3rj3dqL6cc49954rM8NxHKebCdo9AMdxnHbjQug4TtfjQug4TtfjQug4TtfjQug4TtfjQug4TtfjQuh0NJL+r6T/1mTdz0r67wto+/mS7l/86JzVggthByPpEUnTksYljUj6V0lvltTU/26StkkySbnjGINJmpQ0IWmnpA9KChfb3kIxszeb2V8uRVvZv+WMhra/b2ZnLUXbzsrGhbDz+U0zGwBOBd4PvAv41DKP4Vwz6wd+BXg18O+XuX/HaSkuhCsEMxs1s6tJhehSSU8BkPQbku6UNCZpu6T3Nrz2vexzJLPoniPpdEnflXRA0n5Jn5O0pskxPADcBJxXL5P0Mkl3NVisv5SVv1HS1xrq/ULSlxqet0s6L7t/kqTrJB2UdL+kSxrqHeHuSvoTSbsl7ZL0ezOtPGCtpG9kVvStkk7P3qv/Fj/OfotXS7pI0o6Gth+R9MeS7pY0KukLknoW0LezUjEzvzr0Ah4BXjxL+WPAH2T3FwFPJf0/tV8CHgdemX23DTAg1/DuGcBLgCKwkVQs/+YYYzDgjOz+ScBu4G3Z8/nAXuBZQAhcmo25CDwBGMnGdRLwKLAje+8JwHD2XR+wHXgjkMva3A+ck9X9LPDfs/uLgT3Ak4Fe4B9mjO+zwAHgmVlbnwOunO3f0vDb7Zjxe/8wG+864D7gzc307dfKvtwiXJnsIv1DxcxuMLOfmFliZncDnyd1YWfFzB4ws+vMrGJm+4APHqt+xh2SJkmF4QbgY1n5ZcAnzOxWM4vN7AqgAjzbzB4CxkmtxwuBa4Fdkp6U9fd9M0uAlwGPmNlnzCwyszuBfwJ+e5ZxXAJ8xszuMbMp4L2z1PlnM/uhmUWkQnjePP+2mXzEzHaZ2UHgaw3vN9O3s0JxIVyZbAEOAkh6lqTrJe2TNAq8Gdgw14uSNku6Mgt8jJFaNnPWz3ga0E/qlj+L1IqDdN7yHZlbPCJpBDiZ1KICuJHU6rowu7+BVAR/JXuut/GsGW28DjhhlnGcRGo91tk+S509DfdT2bgXwlzvN9O3s0JxIVxhSHoGqRD+ICv6R+Bq4GQzGwL+L6Dsu9lSC/3PrPypZjYIvL6h/pxYyheBm4H3ZMXbgf9hZmsarl4z+3z2fV0In5/d38jRQrgduHFGG/1m9gezDGM3sLXh+eT5xr2EtLNvp8W4EK4QJA1KehlwJfAPZvaT7KsB4KCZlSU9E/idhtf2AQnpnBwN9SeAUUlbgHcucCjvB35f0gnA3wFvzqxSSerLgjcDWd0bgRcAJTPbAXyfdK5tPXBnVufrwBMl/TtJ+ex6hqSzZ+n7i8AbJZ0tqRdoan1hA49z5G+xEI63b6eDcSHsfL4maZzUcvoz0jm9NzZ8/x+B92V13kP6BwtANpf1P4CbMrfz2cBfkLq6o8A3gC8vZDCZAH8PeKeZ3Qb8PvC3pMGPB4A3NNT9Oanofj97HgMeAm4yszgrGwdeCryGdO5zD/AB0oDLzL6/CXwEuD7r65bsq0qTw38vcEX2W1wyX+Ul7tvpYGTmiVmdlUlmNf4UKGbBka7o21l63CJ0VhSSfktSUdJaUsvxa8slRO3s22ktLoTOSuM/kK5dfBCIgdmCKquxb6eFuGvsOE7X4xah4zhdz6KzknQCBRWt59DaXqdjmXWV4txLFw99I83yhRorNJRl90rvLRAEIgmFBZDkIckBhYTBnjKloMb6sAzAcFykbHmGp0sQBQRVCCJQAooMmUFiyIDEAAOzbJWmNazWnOt+Bg1eWHP+2Dy1WuzUjTO838w2Lvb9X31Bnx04GDdV9/a7K9ea2cWL7WuxrGgh7KGPZ+lF7R7GymCmqCxJm/M7FArm6Lfx3YY6qo8zCA6POQjS8kDpe2EAClAuhDCEXIjlc5ALSXoLWD6kOlQg7gkorw2p9YnyeqisTwg3lnnWtkc4vW8fLx+8kxjxlZGn88jUem7+2enk9+Up7Ral/QmFyYTicA3VEsLJKooSqNZQnEAtSgUtijAziOP0OcnuSffxA5AkZAVHPjfWqZPMeLaEY2Ez68/HPO3NxreTLz264Jca2H8w5tZrt85fEcif+OB8u5xawooWQmcOWiF6sHjhm/les8IXZmkPZwpfPoflQqyQJ+nJkfTkqQ7miUsBk5sDan1i4oyI/FCFp2zZxblDOzlQ6+NgtY+dk0P88NFT+dfqE/j70V8mqAT07Be5aThhX0J+KiY/HpObqhGUI1SpQRSjai0VqSgVQIuTVFTqn4mtGuFbeoy4I8YxNy6Eq4lWCSAsjQjOJYBpwdyWXxgcsvwIQ6yYx/IhSU+euC9PVAoprwuJSmJ6s6gNJJxw6gHOXLOPV2/8Ib/cM8ydlT7umN7GSPUsaiNF8qMhAw9DbhpK+2uE5YTcVA1VYoJqBLUIRfGxLb/ZBLBR6DIBnFf8YJUKYIoBSav99+PEhXCl0krRg8UJX7OWX1pwbJc3CCCfgyDASkUsFxD3F4mLIZW1OaoDAdMbxdSJCcmaiG0n76YYRmwAzMS+yT7u2H0ytz62jSQOiMYK5EdC8qNiwx4jP2307K8R1hLCiSqqxagSQRyjWpRaenGMJanYkcTzi99CLD84plgtWPjmaa/dJHTu2MCFcOXRZgE8Ltc3LThaAANBEM5u+YUhSX+BJBdQXVsgytzfyjoob6lx1hm7OHftTt6x4SYA7qis45HqBj728wuZ3N9L6dE8/fuNwphRHIkIKwm5iSqKE4LpGsRJ5vYmEMWQJKn4zWX5HY/bC6va8psLw6h1+DhdCDudTrT8Zr7XrPBBKnSZ8BEI5XKHrD/L57BijqS3QFIMqazNE/UETGwJiHphektEfmiaQjGiN1+jF9g32cf102dy675tlKMc+4cHiKdylB7NMzgOvfsSCmMJuan4sOvbOO9nlgpgHB+e96u7wJCWgc/7HQcGxO4aOwui1cIHSx70mFX8sudDll8YpuVhmJblchAGWCGfRn2LeeJSnqQnpLImT61XTJ4UUBswdPY4J60d5T+cciMXlXaxJw7ZF/fxTwefwb/8/GyS4QL9D4fkpozN+xNyZSM/XiaoxgTT0eE5v1p0pOUXZUs6ZnN7W2j5dbzb24JNFj5H6Byb5RC+Q321ed6vHvENA6yniOVD4v4CcSmksiZHeY2oDonpzQlJj8FgmTCX0JuPmKwWuGrvBdxQnGTX1BD7p/vYtXcN+UeLlMZF7+MJYcUoDkfpvN9kLZ33K9fSeb8oPmz5+bzfHH21RqwMiDt8B5sL4XKxnIJ3qM9ltvwal7uEIQqCIy2/MDhqnd/UxpDqoJjcmlA8ZZxzNu/hj7Z8mx7VKFueXbW1/O3DL2DvSD/779lIYUQUh6E4mrBlyiiMVgnqAY84E74kOSrgYS58s/S1fOLU6c68C2GraIfwQVPil1Zr8bzfjKUucV/x0LxfXBSTm9N5v+qQEffHaKhKT6FGOc5z69TpJBawtzrA45VBdu1Zi0by9O4ThRGjOGoUxmJy5Tiz/BKCcjUNfDS6v3PM+83n/roALnF3mM8RrmraJXaH+m9+q/iyLXQOA6xYICnkSEo5agN5ot6QqY0BtX4xfkZEMFjl1866l/P7H2UgnKYvqHDd6FO45fFt/Hz3Ju6741TCsijtFWHFOHF/Qq6ckB+vElRignJ0OOAx27xffaEzNDXvt+qjvW12S82g1tk66EK4YNotfnWWyvKDpZ/368sT9eWo9YeU1wREvaK8AeKSkV9bYaB/mvWFCfqCCokFjMR97C0PcHCsl9pwkb69AblJ6N2bEFaN4kiNoJoQTGXzfo2Bj+xzMfN+q14Aoe0imCLi+Y/FaSsuhLPRKWIHC7L60urHafllAjhrtDcIjrL8LB8S9RdICiHl9TlqvQGTJ4nyxoTwxGmef9qDrMlPsa3nAFNJgZsPPoGRSonP33sBtek84XCO3ERAcQTWHEwXOhdH0nm/3Hi6v1eN1l+cpLs8liLgMZeILaXb20WW31wcylXRwbgQ1ukk8YPlFcC0YM55v7m2uMV96Y6Pyro8cTFgakNA1A/lzQnBpjJPPHEvv77ubtaEk2wMJ9kVDXF7eAqVOCTa30NxOKC0VxRHEvKTRmEsIqhk835JgqarhwMf2T7fpgQQssXQLoCdgluEnUSniV2dpRC92dpZaFaXIF3fN3OdnzWs84tLOSprU8tvYquI+gzOnGTd4CRPHjrA5uIY+6r9jFR7Gav08L57f4NyJU91tIjKAaXdIbkybNqXkJtOKIzHhFMRYTlC5SiN/FZqzbu9nRLw6EqXtznSBdUd+reXsbqFsFOFr85SCeDMtha5xe2onR5hgJVS9zfuLVDrz1HrD5heH1AbFFOnphleXvuk2zm/91GeWtjD5jDHNVOb+d7ok/jhxCmMbx8kPxawdgeEZejdHxFUE/ITEUE1FT3V4sNJDjLXd64ML0DzArja5vxWkPg1YkDNOjsH9MoXwk4XO1iw4KWvNCl6dY611q8+75cFOY5yeYMAK+YhCEh6U3e3NlQkLgZMb8hRHRRTm43qSTXyfdOcvGGEfBATKP3DvPXANm7ZfxqjlR4qtRwj+/sJD+YpjIh1e43ctNFzMM4EMBW+YHqWqG8cH5nhZTHLXVz8Og5DxB2eDH/lC2EnsgjhS19bnPjBAhOazpzzy4Wp5ZcLiAaLxIVUAKNeMXEyVDZGbDltP68/5VbOLO7hwp4qw0mZayZP44HyZr78wLlMHyzRsyNPcRg2jRjFsZjcdEJuokZQS9B07Ui3N0rFzqLosLs7l+W3mKCHr/PrKBLrbIPFhfB4WaToHX69yfk+mF34YG7xm7m/N58/vMsjnyPpyRH3Foh6s4hvSUydKKJeo7a5Rr6vSn9vhU3FKoPFMj8YOZMfcCafAUaqJX7x+EaqU3mKjxXpn4TSXiM/mVAYzwSwGhOUa7Nmdj4kgDPm/QCsbgm2WwBd/JYEnyNcTRyn4B1uZgmsPlhcXr+e1OpLegvEpRy1/hzltekWt4lTjGgo4unnPMzp/fu5ZM0POSufcH8tYHu0jq8dOI9/3X4a5YM9lB7Lk5uGtY8n5CpGYaRy5P7eepKDGcJ3aJsbpG7vUix3WanCB6ta/I5ExD5HuEJZDuGbq58mLT+YY96vHvHN5yAM03m/fEBtME1wUF4TUh0S1UEob0xISjGlDVMMFqsEMg5W+/j62Hl8N6zws4kT2T09yAOPbyDZ0UvPWEDvXiMsQ8/wjHm/ckNm5/hw4OOYmZ193m/VY0Dic4QdzBKJXdpUE6b/XP3NF+VteD5mWqtcOt9Hob7Or77QOd3fO7EloDpk1E6ucOpJB3jauu28et2tAEwlRXZGa/n87mfy8Mh6vv3Yk8mPhRT3i+KosX7CKI7GhJVautB5rsSmbQh4dLToQdcJ30zMRNXCdg/jmHSfEC6XpTdfn824vA3Pzcz7WSGPFdOlLnExXegcFcX0JhGVoLw5hoGItesmWN8zSSBje219luVlDdvL63hw3wbK40V6Hs9RGIOeA5bO+U3Fh5e8NAY+zHzeb86+ulsAG0l8jrANdIrY1ZnRTtNWX93lnSOhqeVCkp4CVgyJ+vJUB3NU+9OzPGoDUDmtQmmgzMXb7uPM0uNszI3TF1S4efIMfjJ6Et/deSZX7bkATYWUHg8IKzC4z1hbMYqjNcJyTDhVI6hE6Vq/YwU8YGnm/Tzau+pIgyXuGree5XZxm+13KQSwvtwllwPp0Hq/+kLnqL9AVAqpDoZU1ojqgChvMqKBmA0bxtnYN8E5vbs4vbCXQKkoTMUFHp8aYGSkj+LuHLlJ0bfb0sSm9XM9ZgY+6olNs/M8mnZ/u8HyAxfBY+LBktaz1IuVF9L+HO3M6uqmXxwqOyR6cDitVX13Rz25QRbwsHwutfyygEdSCJhenyMqwdQJorouIXfiFOdu2cmm4gRP6dvBVFLk/qnNjNZKfOyBC5kqFykfKBFMBRQPBhSHYf2k0TMcE1aM/Fia4CCYmmW9Xz2r8zIGPFz4Vg8eLOkgllX8YPECGATpQucgE8F64KM/FcDK2hxxUUxvFFEflE+K6N04yfkn7uSSjT9kUzjOGfkyu+KQ3dUhhqu9HNw3SDico393QHHEKI4lFMZiwkpMbqIGUZOJTZdCAFdytBdcABdJ7Auql4+OELuG744QvYb1fQQ6PN8npft6A2XzfgFJT56klCMq5agOhlT7xNQJ6ULn6LQyvX0VztqwlxN6xqlZQDXJMVrt4UOPvISJSpHRiR5q03nyewqE02LdHiM3DT0jEbmpmHA6IpiOsrN8q0fM+zW13GUJAx4+77f6MUTNOltqOnt086EFiN8C5/NgHuFLKxz13eF5wAarT4fn/Q65vQ0CSCaAVsyT5AOi/jxRb0C1P6C8LqA6CNOn1CgMVXjVE+/m7NIuXtj7EFvCXm6qBPx4+lS+uffJPLJ9I8FIjv7tAQNTRml/eqBRYbyGqgnhdEOCg7kyOy/W8oPWBj5c/FYsHixpB60UvIbyowSv3m9Y/wwPp7XP3F3LhVgQYMVcenB5Kc3wEvXlSPJiel1IrS/N5lzZEMNQlRM3j7A2jBkqlAmU8ODEBh6c2MAXowuoJSHbD6yhMtpD/kCOwcdFbtLo3R8TVhLyozWCKCGYqh65zS2Km8/w0s6or7u9qwJD7hq3Fi3YxV0SK6/eZz2yWy+rW3xweJlLPZ19LiQp5LB8QNybJ8mJqD8kyYnKYEDUI6ZOMmprY9afOszLTvoFT+97hJf3Pc6E1birsoaHqpv49MPP5eBoH8EjJYojov+AsX4sIT8ZkR+PUJQQzhS+Y7m99YPMWxD0cLfXqePBkuWiGdGDuef1Zopevc1jiV7jQUZBWmb5hnx+uYCkmEuDHT0hUSkk7kmFLy5CZa2Ie4zKphj1RvQPTrOhp8JQsczu8hDfqZ3D7ZPbOFjt4/6RTYxMlZh+ZID8hCjtEYWJNMtLfjwmLMeHI74zj7Scb94P5j/TwwXQWSRm+PKZllMXpKPKFyh4cOT6vYZnSYfz+tXvw/Tectl8X93tLeVJcgFxKXV3o76QqChqfaI6mEV6N8VYX8wTTtnLib1j/O6mmzgzP8xokmfS8nxl5Ol8f8/p7DswQO6xHnKTovS40V82NmT7e3OTEUE1QpUYVWuz7u+1BS53SYvqZS58ztKQBkt8i13LELMsUoaFW3r1d+YSvvDwwUYWZktcwgALAsgFqeVXCLEwoDaQCmB1IEgFcFDUeiEaMGpDEfTE9K+ZplSoMZCvAPDj8ilsr63nsep6hmu93PL4NvbtWkPuYI6evSI/ZZQOJum831g27zc9I7PzXPN+cPzurwugc5x4sKSVNAYjDhXNM5+nhqwt0BDVbbDy6sKXWXuWz6y9fCp6lg9IcgFJPiDJi7ggan0BcQHK60XcA+UTIoL+GqeccJAnr9nDWb17eFbvA4QYMWJXtJar9l3A7qlBbrr/IjSeo2dvSH4cCmPG1tGEsBwdFr7ZAh71XR7LFPBw4XMWgyFPzNpyGk9em+niwhGWXvpVcLSLGwTpMpbs5DbLNwqgSAohhCIuhiShSIoizit1fXtEXITqkIgLUFmfYMUkTWvVW+bk/mFOKI4yEE6TWMCU5TkQ9/NodQMPj63j4HgfuccLFMZEaZ9RGDcK4zG5yTg90W2qCrEtfL0fzD/vB60TQY/4Og24RdhKAqFCvnm3NhA2m9jlMguvEKYWXikgCVORszDN3JLkRNQLcQHiXiMqGUlfTM+6Mmv6p7hw06NsyE9wds8u+oIKB+J+JpMi906dxF2jW/nGxJPZPzxANJknvy9HblqU9hoDZegZiQnL2YFGlQhVI1SJII6PO+AByzTv55afMwcGJB4saSU6nIwU5nZz69vW6sIX1j8DkkKDi1sMiPMiKokkB1GvsBBqvWB5iHqNuGhYKSbsixjoK7Nt7TAnlkZ5/sDP2ZgbY1tugjxwby1iT7SG8VoPuycH2XdwEO3soWdC9O0ycuXk0IFG9cBHUI4aDjJvMrEpuAA6HY48Vf9MJJ0M/D9gM+n/WVxuZh+WtA74ArANeAS4xMyGj9lYEKCBviPEzsLM6susPCukn3FPQJITtd7ssw+SQmrtxUWIS0bUl2DFmPxglXwhYtPgBKVcjZP7hukPK6zPTzKUmyIkIa+Y0biX3dUhxqIePrPreUxHefaO91Ot5qgO9xBMBxRGAvLjMDRh9IwYYSWmMBoR1BLCySpEyZFu72zzftCdAQ8XvlWBgUeNZyEC3mFmd0gaAG6XdB3wBuA7ZvZ+Se8G3g2865gtBWlaqmO5uanFJ2q9IsmlaaqSAtT6IS4aUd9hC2+of5qBngrbBg+wJj/NU/p2sj6c4MzCXtYEEUNBSK8KVKxG2WLur5W4MTmbg9U+Hj6wjvJUgWBnD7kpMTQMuSmjMJGQn0zITcdpaqss4jvrUZaLOMg8LVoGAXTLz1kkZnLXeCZmthvYnd2PS7oP2AK8Argoq3YFcAPzCGFSCJnatoa4lLq0td40cBH1ZfN5PanQJcWEYKBKLh+zbnCSnlzExtIEA7kKA/kyvUF6VkdeqdWVZPnTHixv4he2mevjs6lZwGRUpBznOFDuY2SqxMRkD/FwkWAqoOeA6K9AcdgIq+lJbkE1zewclusJDhoEcJ6DzG2m4LXD+nPxc5aIpVxQLeli4MNACHzSzN4/4/tTSDVkTVbn3WZ2zbHabOscoaRtwPnArcDmTCQB9pC6zrO9cxlwGUChby1Tm3LUBtKIbXUoc3GHahTXlukvVTh5cJS1xSme2r+ToXCKp/ZsZ01QZXMY0KsCQTZ3MZaU2ZcY++ISP6ucxP5ogJ+Mb2Gs1sP2kTVMV/JUxoqoHJIfCSiMiP4pKI4mhNWE/ERCUEstP8VJNt+XHLnYuZ7g4FiWH3RPtNfFryswli5Vv6QQ+CjwEmAH8CNJV5vZvQ3V/ivwRTP7uKRzgGtIp9zmpG1CKKkf+CfgrWY21rjg2cxM0qx/JWZ2OXA5QPG0rbb/BVWKfVUK+YhNpTK9+SqDhTJrC1PklVAKU2tvNC4xGpfYUV1HqISahcQWMBEXmYyKjNZ6GK70MlXLMzzRS1QLqY0VUBQQjgcENeidErky5CZTlzesGPmJmKBmhNPp8ZVBJd3ve9RpbvO5vrBkAuji53QWS5qh+pnAA2b2EICkK0m9yUYhNGAwux8Cds3XaFuEUFKeVAQ/Z2Zfzoofl3Sime2WdCKwd752tg3s55MX/h2n5qYYCELyhOQVMpFUGLeEfXGBB2sbORj189PJrYzUSjw8to6pSoGxsRLJdI5gKiScFmFZ5KYhqEFpylAMuWkjiCGsJig2wnJq/QXVw4KnWrawuRahxA6v85svqzO0d7Gzi5+zTKTLZ5q2CDdIuq3h+fLM+KmzBdje8LwDeNaMNt4L/Iuk/wz0AS+er9N2RI0FfAq4z8w+2PDV1cClwPuzz6/O11ZiYiTp5UClH4DxpMRkUmQ46mN/rZ+D1T52Tw8yUS2yf7yPWjVHNFZANZGbCChURFiGsAxBFXJlI4jSTyVGWP+sJCgxgkqciV9CUI2OFMDs4CKf92vsywXQWfBe4/1mdsFxdvla4LNm9r8lPQf4e0lPMZv7P/52WITPA/4d8BNJd2Vl/4VUAL8o6U3Ao8Al8zVUtgI/njqVW4ZPY99UH/sODhKP5wknAvITQSpu06AIeqczK69ct/JSl1aRpZ+JEdRSwQqiJM3eEqUWW/2TKJ3/O+Tu1i2/xgOM5trmlj6kn8slfL67w+kQljAN107g5IbnrVlZI28CLgYws5sl9QAbOIaX2Y6o8Q9gzpnTFy2krcm4wB2jJ/PQgfVMTxbgQJHChMhNivwkBDUjNwVBbKmVF5NZdxBUk0Pipzh1fYkSZA2f9Tm9OE6tviSz8JLkkFt73Gd6gM/7OauaNA3Xki2o/hFwpqTTSAXwNcDvzKjzGKmWfFbS2UAPsO9Yja7onSVT4z3c/f0zKY6IgSyIkSsbuUpCbjpBUebWxpbO6RnpnF7dyjsUvMgsv7qVd0jU6vdziB50TsTXhc/pYJYq6YKZRZL+ELiWdGnMp83sHknvA24zs6uBdwB/J+ltpFOUb7Cj/giPZEULoSLo2S8KY0ZYhfxUGskNqmnKKkUJQTW15lSNIAHV5/LqVp41XHGDBdcgaE0LYOO71B9XkfvrAugsgjT7zNKtI8zWBF4zo+w9Dff3kk7BNc2KFsKwCkOPxITT6Rq+Q+JXi1PLL7ajha/+PNPamylyM5+hMwIePu/nrDAMqPnOktahyNJ9u5U4dX+r2Rq+ugDGSbqWr3G+r3F+r3FeDxpEzZoTv4YyF0DHmQvfYtdSFCfkRytp2qrYDu3cUHxY7A5Fd2cTvzmED1iY5dfw3iGOV/xc+JxVxFLtLGkVK1sIEyOYqh4tgHNZfpDu6oCj5vpgfvE7ok5jG4e+XGGWn4ufswwscdS4JaxoIcQMlauzWn9WF6/6+r5ZAh1p8dFu7oIE0MXPcebFXeNWkhhUa4e2sc3p9kLz4tdQ1jLrz91ep4vwM0tajh3O4LyQeT84pgAeXXeJFjy7ADpdiAGRW4QtxAzL9vYuSvgay2fWb2gn/XIFiJ8Ln9OhuGvcauYTwSYE8Ij6DW0c/rLDRdAF0OlkzF3j1mIGtWh2y6/+/WzlNLH8BY4Sso4RPxc+ZwVh+PKZ1mILm/dLv5pFRJoMhMw/nhaLoAugs0Jxi7DVNCY5qD83MOde6yaPuJzXCnTxc5xjYrgQtp7jtf4OVe4wEXQBdFYJhogSD5a0jmNleqlzLDHrtCCIi5+zSvE5wmVgKQQwLXYRdJwlx9w1binGPMtejqg8t4C5ADpO6/A5wuXCBdBxOhoXwlazgODHkV+7CDrOcmCI2IMly0gTwtU2AXTxc7oYD5YsF24BOk5HYh4saTW2NAKYVlyC8cxs0wXQcQDMhbB9uAg6TifgSReWnbZnhnYBdJyjcItwGWm7CDqOcxTpKRouhC2nIwTQLUHHmROPGrcSW6AItmwcHTAGx+lQ0h1gLoSdgc8HOk6b8GBJZ+Ai6DhtpdP/XFa/ELoIOk7bcde4XXhQxHE6gjRq7HuNlx8XQcfpKDr9T2d1CaELoON0JO4aO47T1RjqeCFsm+MuKZR0p6SvZ8+nSbpV0gOSviCp0HRjlrQuKOLWoOMcN9bk1S6aFkJJvUvc91uA+xqePwB8yMzOAIaBNy1xf47jtAMDS9TU1QySLpZ0f2Y0vXuOOpdIulfSPZL+cb425xVCSc+VdC/ws+z5XEkfa2rEc7e5FfgN4JPZs4AXAldlVa4AXtlUY24JOk7HY6amrvmQFAIfBX4NOAd4raRzZtQ5E/hT4Hlm9mTgrfO124xF+CHgV4ED6T/Ifgxc2MR7x+JvgD8B6iq2Hhgxsyh73gFsme1FSZdJuk3SbTUqxzmMWXABdJwlp25bzHc1wTOBB8zsITOrAlcCr5hR5/eBj5rZcNq37Z2v0aZcYzPbPqMobua92ZD0MmCvmd2+mPfN7HIzu8DMLshTXOww5mp8adtzHOfQXuMmLcINdUMnuy6b0dwWoFGPZjOangg8UdJNkm6RdPF8Y2wmarxd0nMBk5Tn6Lm9hfI84OWSfh3oAQaBDwNrJOUyq3ArsPM4+lg4LoKO0xoMaD5qvN/MLjjOHnPAmcBFpFryPUlPNbORuV5oxiJ8M/CfSFV3J3Be9rwozOxPzWyrmW0DXgN818xeB1wPvCqrdinw1cX2scABuQg6TotZQtd4J3Byw/NsRtMO4Gozq5nZw8DPSYVxTuYVQjPbb2avM7PNZrbJzF5vZgeaGvLCeBfwdkkPkM4ZfqoFfRyJC6DjLAPNRYybjBr/CDgzW25XIDWmrp5R5yuk1iCSNpC6yg8dq9F5XWNJH5mleBS4zcyOy2ozsxuAG7L7h0gnQpcHF0HHWT6W6M/NzCJJfwhcC4TAp83sHknvI9Wkq7PvXpqtdomBd85nvDUzR9gDPAn4Uvb8b4GHgXMlvcDM3rqof1G7cAF0nOXFlnaLnZldA1wzo+w9DfcGvD27mqIZIfwl0vU4MYCkjwPfB34Z+EmzHTmO08V0uP3RTLBkLdDf8NwHrMuEsQUL+VqEB0Ucp42oyas9NGMR/i/gLkk3kI70QuB/SuoDvt3CsTmOs1ro8EMj5xVCM/uUpGs4HMj4L2a2K7t/Z8tGtlS4Feg47WVh6wjbQrNJF8rAbtJkCGdIOt4tdsuDi6DjdARLuI6wJTSzfOb3SHeTbAXuAp4N3EyaJKFzcRF0nM6hw/8cm7EI3wI8A3jUzF4AnA+MtHJQx42LoON0FqbmrjbRTLCkbGZlSUgqmtnPJJ3V8pEtBhdAx+lI1OF/ms0I4Q5Ja0i3rVwnaRh4tJWDchxnFWGCJpOutotmosa/ld2+V9L1wBDwrZaOaqG4Jeg4nU2H/4ku6PAmM7uxVQNZNC6CjtP5dPifqZ9i5zhO63EhdBynq1kBC6pdCB3HaTkrNmosaZzZDVqRZroZbNmoHMdZXaxUITSzgeUciOM4q5cVaxHORNIm0iStAJjZYy0ZkeM4q48OnyNs5oD3l0v6BWlW6huBR4BvtnhcjuOsFmwBV5toZq/xX5ImWvi5mZ0GvAi4paWjchxndbEKhLCWHXwSSArM7HrgeM8ddRyni1DS3NUumpkjHJHUD3wP+JykvcBka4flOM6qosODJc1YhK8ApoG3ke4xfhD4zVYOynGc1YOs+atdNJN0odH6u6KFY3EcZ7XS4VHjZjJUNy6sLgB5YNIXVDuO0zQd7ho3YxEeWlgtSaSu8rNbOSjHcVYXnb6gutnDm4B0X52ZfQX41dYMx3GcVYetgqixpH/T8BiQLp0pt2xEjuOsPjrcImxm+UxjhDgi3VnyipaMxnGc1ckqEMJPmtlNjQWSngfsbc2QHMdZbayGOcL/02SZ4zjOiuRY+QifAzwX2Cjp7Q1fDQJhqwfmOM4qosMtwmO5xgWgP6vTmJtwDHhVKwflOM4qwtobEW6GYyVmvRG4UdJnzczPMXYcZ/F0uEXYzBzhJ7MD3gGQtFbSta0bkuM4qwnR+XuNmxHCDWY2Un8ws2Fg0/F0KmmNpKsk/UzSfZKeI2mdpOsk/SL7XHs8fTiO00GsgnyEiaRT6g+STuX4h/xh4Ftm9iTgXOA+4N3Ad8zsTOA72bPjOCudJc4+I+liSfdLekDSnDoh6d9KMknz5k9tZh3hnwE/kHQjqZX7fOCy5oY86+CGgAuBNwCYWRWoSnoFcFFW7QrgBuBdi+3HcZwOYomCJZJC4KPAS4AdwI8kXW1m986oNwC8Bbi1mXbntQjN7FvA04AvAFcCTzez45kjPA3YB3xG0p2SPimpD9hsZruzOnuAzbO9LOkySbdJuq1G5TiG4TjOcrGEFuEzgQfM7KHMiLqS2Xe6/SXwAZrcDtxs0oWYdCfJGHCOpAubfG82cqTC+nEzO5802/UR5q2ZzTljYGaXm9kFZnZBnuJxDMNxnGWj+TnCDXVDJ7tmep9bgO0NzzuyskNIehpwspl9o9nhNZN04fdITcytwF2kKbhuBl7YbCcz2AHsMLO6yXoVqRA+LulEM9st6UR8C5/jrA4WFgjZb2aLPhNJUgB8kGzqrVmasQjfAjwDeNTMXgCcD4wscHyHMLM9wHZJZ2VFLwLuBa4GLs3KLgW+utg+HMfpLJbQNd4JnNzwvDUrqzMAPAW4QdIjpIbb1fMFTJoJlpTNrCwJSUUz+1mDiC2W/0x6EFQBeAh4I6kof1HSm4BHgUuOsw/HcTqFpVsa8yPgTEmnkQrga4DfOdSN2Siwof4s6Qbgj83stmM12owQ7sgWVH8FuE7SMKlQLRozu4vZjwR90fG06zhOZ7JUW+zMLJL0h8C1pDkPPm1m90h6H3CbmV29mHabSdX/W9nteyVdDwyRnmbnOI4zP0u8WNrMrgGumVH2njnqXtRMm81YhI2N3riQ+o7jOMquTmZBQug4jrMoOjzpgguh4zgtp9MzVLsQOo7TelwIHcfpalZyYlbHcZwlwy1Cx3G6HZ8jdBzHcSF0HKfbcYvQcZzuxliyxKytwoXQcZyWUj+8qZNxIXQcp/W4EDqO0+3IOlsJXQgdx2ktbT6qsxlcCB3HaTk+R+g4TtfjW+wcx3HcInQcp6tp/mCmtuFC6DhO63EhdBynm/EF1Y7jOICSzlZCF0LHcVqLryN0HMfx5TOO4zhuETqO43iwxHGc7sYAT7rgOE6343OEjuN0Nb6O0HEcx8xdY8dxHLcIHcdxXAgdx+l23CJ0HKe7MSDubCV0IXQcp+V0ukUYtKNTSW+TdI+kn0r6vKQeSadJulXSA5K+IKnQjrE5jtMC6pHj+a4mkHSxpPszrXj3LN+/XdK9ku6W9B1Jp87X5rILoaQtwB8BF5jZU4AQeA3wAeBDZnYGMAy8abnH5jhOa5A1d83bjhQCHwV+DTgHeK2kc2ZUu5NUX34JuAr4X/O12xaLkNQlL0nKAb3AbuCFpIMGuAJ4ZXuG5jjOkmILuObnmcADZvaQmVWBK4FXHNGd2fVmNpU93gJsna/RZRdCM9sJ/DXwGKkAjgK3AyNmFmXVdgBbZntf0mWSbpN0W43KcgzZcZzjQIBia+oCNtT/vrPrshnNbQG2NzzPqRUZbwK+Od8Ylz1YImktqYKfBowAXwIubvZ9M7scuBxgUOs6fArWcRwANb+zZL+ZXbAkfUqvBy4AfmW+uu2IGr8YeNjM9gFI+jLwPGCNpFxmFW4FdrZhbI7jLDVLm6F6J3Byw/OsWiHpxcCfAb9iZvO6ju2YI3wMeLakXkkCXgTcC1wPvCqrcynw1TaMzXGcJafJiHFzVuOPgDOzVSYF0kDr1Y0VJJ0PfAJ4uZntbabRdswR3koaFLkD+Ek2hsuBdwFvl/QAsB741HKPzXGc1rBUUePMY/xD4FrgPuCLZnaPpPdJenlW7a+AfuBLku6SdPUczR2iLQuqzezPgT+fUfwQaUTIcZzVxhJmnzGza4BrZpS9p+H+xQtt03eWOI7TWox6RLhjcSF0HKf1dLYOuhA6jtN6FrB8pi24EDqO03pcCB3H6WoM8MObHMfpZoS5a+w4jkPS2SahC6HjOK3FXWPHcRyPGjuO43jU2HGcbscPeHccp9vxU+wcx3F8jtBxHMddY8dxuhwDEhdCx3G6Gg+WOI7juBA6jtPlGBB39tYSF0LHcVqMgbkQOo7T7bhr7DhOV+NRY8dxHNwidBzHcSF0HKe7MYM4bvcojokLoeM4rcctQsdxuh4XQsdxuhvzqLHjOF2OgfmCasdxuh7fYuc4Tldj5sd5Oo7jeLDEcZyux9widBynu/HErI7jdDuedMFxnG7HAOvwLXZBqxqW9GlJeyX9tKFsnaTrJP0i+1yblUvSRyQ9IOluSU9r1bgcx1lmLEvM2szVJlomhMBngYtnlL0b+I6ZnQl8J3sG+DXgzOy6DPh4C8flOM4yY4k1dbWLlgmhmX0PODij+BXAFdn9FcArG8r/n6XcAqyRdGKrxuY4zjLT4Rbhcs8Rbjaz3dn9HmBzdr8F2N5Qb0dWtpsZSLqM1GoEmPi2XXV/i8a6lGwA9rd7EAvAx9taVtp4zzqel8cZvvbbdtWGJqu35XdpW7DEzEzSgm1hM7scuLwFQ2oZkm4zswvaPY5m8fG2lpU43uN538xmTpF1HK2cI5yNx+sub/a5NyvfCZzcUG9rVuY4jtNyllsIrwYuze4vBb7aUP67WfT42cBogwvtOI7TUlrmGkv6PHARsEHSDuDPgfcDX5T0JuBR4JKs+jXArwMPAFPAG1s1rjaxolx5fLytxsfbYcg6fOuL4zhOq1lu19hxHKfjcCF0HKfrcSFcQiSdLOl6SfdKukfSW7LyWbcWdgqSQkl3Svp69nyapFuzLY9fkFRo9xjrSFoj6SpJP5N0n6TndPLvK+lt2X8LP5X0eUk9nfT7+lbYFBfCpSUC3mFm5wDPBv6TpHOYe2thp/AW4L6G5w8AHzKzM4Bh4E1tGdXsfBj4lpk9CTiXdNwd+ftK2gL8EXCBmT0FCIHX0Fm/72fxrbBgZn616CJdHvQS4H7gxKzsROD+do+tYYxbSf9jfyHwdUCkq/tz2ffPAa5t9zizsQwBD5MF+RrKO/L35fCOqXWkKzS+Dvxqp/2+wDbgp/P9nsAngNfOVm+lX24RtghJ24DzgVuZe2thJ/A3wJ8A9Y2e64ERM4uy5/p2x07gNGAf8JnMlf+kpD469Pc1s53AXwOPkW4XHQVup3N/3zoL3Qq74nEhbAGS+oF/At5qZmON31n6f6UdsWZJ0suAvWZ2e7vH0iQ54GnAx83sfGCSGW5wh/2+a0kTipwGnAT0cbQb2tF00u/ZSlwIlxhJeVIR/JyZfTkrnmtrYbt5HvBySY8AV5K6xx8mzf5TX2zfSdsddwA7zOzW7PkqUmHs1N/3xcDDZrbPzGrAl0l/8079fet03VZYF8IlRJKATwH3mdkHG76aa2thWzGzPzWzrWa2jXQS/7tm9jrgeuBVWbVOGu8eYLukejaUFwH30qG/L6lL/GxJvdl/G/XxduTv20D3bYVt9yTlarqAXyZ1I+4G7squXyedd/sO8Avg28C6do91lrFfBHw9u38C8EPSLY9fAortHl/DOM8Dbst+468Aazv59wX+AvgZ8FPg74FiJ/2+wOdJ5y9rpBb3m+b6PUkDaR8FHgR+QhoNb/tvvBSXb7FzHKfrcdfYcZyux4XQcZyux4XQcZyux4XQcZyux4XQcZyux4XQWTCSLmrIVPNySXMmOciyxfzHRfTxXkl/fDzjdJxmcSF0DiEpXOg7Zna1mb3/GFXWAAsWQsdZTlwIuwBJ27L8fZ/LcvhdJak3++4RSR+QdAfw25JeKulmSXdI+lK2bxpJF2dt3AH8m4a23yDpb7P7zZL+WdKPs+u5pOfUnC7pLkl/ldV7p6QfZTnt/qKhrT+T9HNJP2COs3Ql/WaWy+9OSd+WtDkr35jlzrsnS8bwqKQN2Xevl/TDbAyfWIzgO6sbF8Lu4SzgY2Z2NjDGkVbaATN7Gukugv8KvDh7vg14u6Qe4O+A3wSeDpwwRx8fAW40s3NJ9wDfQ5oU4UEzO8/M3inppaT57J5Jukvk6ZIulPR00m1+55HuxnnGHH38AHi2pUkXriTNnAPp4WDfNbMnk+5BPgVA0tnAq4Hnmdl5QAy8bv6fy+km2nbAu7PsbDezm7L7fyBNGPrX2fMXss9nA+cAN6VbYykANwNPIk0e8AsASf9AmphzJi8EfhfAzGJgdJZs0S/Nrjuz535SYRwA/tnMprI+rp7j37EV+EKWDKBAmp8Q0u2Nv5X1/S1Jw1n5i0jF+0fZv6lE5yRlcDoEF8LuYeZeysbnyexTwHVm9trGipLOW8JxCPj/zOwTM/p4a5Pv/x/gg2Z2taSLgPc20d8VZvanCxum0024a9w9nCLpOdn975C6mDO5BXiepDMAJPVJeiJp0oBtkk7P6r12lnch3aj/B9m7oaQhYJzU2qtzLfDvG+Yet0jaBHwPeKWkkqQBUjd8NoY4nPrp0obym8jOyc7c77ol+h3gVVkf9fM4Tp2jbadLcSHsHu4nPUPlPlKROOq8CTPbB7wB+Lyku8ncYjMrk7rC38iCJXO5lm8BXiDpJ6SZmM8xswOkrvZPJf2Vmf0L8I/AzVm9q4ABM7uD1EX/MfBN4Edz9PFe4EuSbidNeV/nL4CXKj2E6LdJMyuPm9m9pPOe/5L9m64jTT/vOIfw7DNdgNJjA75u6QFCqxJJRSA2syizfD+eBUccZ158jtBZLZwCfFFSAFSB32/zeJwVhFuEjuN0PT5H6DhO1+NC6DhO1+NC6DhO1+NC6DhO1+NC6DhO1/P/A1TooTZEI85sAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using pretrained weights\n",
      "0\n",
      "test 0.00043754806\n"
     ]
    }
   ],
   "source": [
    "model, t, v, tt, trloss, trcorr = trainWeightingLinear(iterN = 500, cv=7, vcv = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Test Correlation')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAArq0lEQVR4nO3deXxV53Xv/8+ShAbQgIQkBkkgEAKMGY3AGA/xWJPU8Tw3+SWte52kdpN73bhJfu11b91f703S+0ubtL5JnNROm9YDHoiJY8dxPAYbjMRkMyNGSQg0gcQkoWHdP86GyLIQR6DDkc75vl+v8+KcZ+99ztqyfJb28+xnPebuiIiI9JQQ7QBERGRwUoIQEZFeKUGIiEivlCBERKRXShAiItIrJQgREelVRBOEmS02s61mVmlm3+xjv9vMzM2sLHhdbGbHzWxd8PhRJOMUEZFPSorUG5tZIvAYcB1QDZSb2TJ339Rjvwzga8AHPd5ih7vPCffzcnNzvbi4+JxiFhGJN6tXr25w97zetkUsQQALgEp33wlgZs8ANwGbeuz3d8B3gIfP5cOKi4upqKg4l7cQEYk7ZrbndNsi2cVUAFR1e10dtJ1iZhcBRe7+q16On2hma83sHTO7vLcPMLP7zazCzCrq6+sHLHAREYniILWZJQDfA/6il821wHh3nws8BDxlZpk9d3L3x929zN3L8vJ6vUISEZGzFMkEUQMUdXtdGLSdlAHMAN42s93AQmCZmZW5e5u7NwK4+2pgBzAlgrGKiEgPkUwQ5UCpmU00s2TgbmDZyY3u3uzuue5e7O7FwErgRnevMLO8YJAbM5sElAI7IxiriIj0ELFBanfvMLMHgdeAROAJd99oZo8CFe6+rI/DrwAeNbN2oAv4srs3RSpWERH5JIuVct9lZWWuu5hERPrHzFa7e1lv2zSTWkREehXJeRAiZ+3YiQ521B3lQEsr9UfaONzaTlt7Fx1dzvDkRNJTk0hPSSIvPYXcjBTy0lMYOXwYZhbt0EVihhKEDAq1zcdZvr2B9yobWFd1iD1Nx+hv72dSgpGbnkJeRgq56cmMzkxlUt4IJuenU5KXTmH2cBITlEBEwqUEIVHTfLydZev38dLaGir2HAQgNz2Zsgk53HpRIVNGZzBuZCq56SlkpCaRkpRIUoJxrL2To20dHG5tp/7wCRqOtFF/uO3j/x5p46OaZhrKT5z6vLRhiUwZk8H0sRlcMDaTC8ZmMm1MBhmpw6L1IxAZ1JQg5LxrONLGE8t38fMVezjc1kFpfjoPXz+Vay7IZ+rojDN2E6WnhLqXRmemMjm/7886dOwEO+qPUFl3hK37j7C5toVXN+zn6VW/n+RflJPGjHFZXDk1j6um5ZOfkToQpyky5ClByHnT2eX8+4rd/O/XtnKsvZPPzBjLlz41iZkFWREbOxg5PJl5E3KYNyHnVJu7s7+llc21LWyuPcym2hbW7DnIqxv2AzC7aCTXXZDPNReMZtqYMycskVil21zlvKhqOsbXnlnLmr2HuGJKHo/cMJ3J+enRDusUd2dz7WHe2HyA324+wPrqZgCy0oZxwdgMirKHMyYrlfzMVMYEj9GZKYxKT9G4hgxpfd3mqgQhEffaxv18/bn14PB3N8/gpjnjBv1f5XUtrby1tY51Vc1s2d/CvkPHqT/cRleP/10SE4z8jBQKs9OYPjaTC8dlMasoK6yuMpHBQAlCosLdeeytSv73b7YxuzCLf7n3Iopyhkc7rLPW2eU0HGljf3Mr+1taOdDSyv7mVg60tLGn8Siba1s4eqITgDGZqVw1LY/FM8ZyackokhI15UgGp74ShMYgJCLaOjr5y+c/5KV1+7h5zji+fdssUoclRjusc5KYYIzOTGV0Ziqze9ne1eXsbjxKxZ6DvLWljl+ur+XpVVWMGpHMH84ay42zx3HR+GwS1CUlQ4SuIGTAtbZ38qWfr+adbfU8fP1U/uzKkrjsbmlt7+SdbfUsW7eP324+QFtHFwUj0/jDWWO5ojSPsuLsIZ80ZehTF5OcN0fbOvjTf6tg5a5G/uctM7lnwfhohzQoHGnr4Dcb97Ns/T7eq2ygvdNJSUpgdtFI5k3IZt74bC6akE3OiORohypxRglCzovDre184YlVrK9u5v+/YzY3zy0480Fx6GhbBx/samT59kZW7z3IxppmOoLR74m5I7ikZBSXTc5lUckoRg5XwpDIUoKQiDt+opMvPLmKNXsO8i/3zmXxjLHRDmnIaG3v5MPqZtbsPUj5riY+2NXEkbYOzGBWQRaXTs7lstJc5k3IJiVJXVIysJQgJKLaOjq5/99X8+72er5/91xunD0u2iENae2dXayvOsTyygaWb29gbdUhOruc1GEJLJg4iktLRnHp5FwuGJupORhyzpQgJGI6Ort48Km1/Hrjfr5z20zumq8xh4F2uLWdVbua+N32BpZXNlBZdwQITeJbOCmHRSWh7qjJ+elxeTOAnBvd5ioR0dXl/OXzH/Lrjft55IbpSg4RkpE6jGsuGM01F4wGQpP4Vuxs5P3KRt7f2cBrGw8AkJuewqKSUcEjl6KcNCUMOSdKEHLW/ucrm3lxbQ1/cd0U/uSyidEOJ27kZ6Zy05wCbpoTugmgqukYK3Y08v6OBt7b0ciy9fsAKBiZxqKSUXxqah6Xl+aRlaaqtdI/ShByVv7t/d38dPkuvriomAevnhztcOJaUc5winKGc+f8ItydHfVHeH9H6ArjN5sO8NzqahITjHkTsrl6Wj5XT8unVN1REgaNQUi/vb7pAF/6eQXXXDCaH31ungZKB7HOLmdd1UHe3FLHm1vq2VzbAoSuLk4mi0tKRmnCXhzTILUMmI+qm7nzxyuYMjqdp+9fyPBkXYQOJbXNx3lrSz1vbqnjvcoGjrd3kjosgUUluVwVJIyCkWnRDlPOIyUIGRANR9r47D8vJ8GMpQ8s0sI6Q1xreycf7GrirS11vLmljr1NxwCYMjqdq6blc9XUfC4an01ykgoNxjIlCDln7Z1dfO6nH7Cu6hAvfGURMwqyoh2SDCB3Z2fD0VPJYtWuJjq6nPSUJC4pCc29uKw0l5I8jV3EGt3mKufs73+1mQ92NfFPd81RcohBZkZJXjoleen86eWTONzazvs7Gnl7az3LK+t5fVPoVtrRmSlcNjmPK6bkcunkXHLTU6IcuUSSEoSc0Qurq/nZ+7u577KJqq8UJzJSh3H9hWO4/sIxAOxtPMZ7O0IT9d7YcoAX1lQDMLMgtJb3p6bkMadopNa9iDHqYpI+bdrXws3/5z3mjc/m5/ct0BeA0NnlbKhp5t1t9by7vZ41e0OlQEYOH8bVU/O5dvpoLi3JJWu45l0MBVEbgzCzxcD3gUTgp+7+7dPsdxvwPDDf3SuCtm8B9wGdwFfd/bW+PksJYuAdaevgxn9eztETHbzy1csZpe4E6UXz8Xbeq2zgt5sO8ObWOg4dayfBYFbhSC4vzeWyybnM1WD3oBWVBGFmicA24DqgGigH7nH3TT32ywB+BSQDD7p7hZlNB54GFgDjgN8CU9y983SfpwQxsNyd//bsOpat38dT/2UhCyeNinZIMgR0dHaxtuoQv9vewO+217O+6hBdDsOTE7l4Yg6Xl+bxqal5TModocHuQSJag9QLgEp33xkE8QxwE7Cpx35/B3wHeLhb203AM+7eBuwys8rg/VZEMF7p5rmKan6xbh8PXTdFyUHClpSYwPziHOYX5/DQdVNoPt7Oyp2NLN/ewHuVDby1dRO8DEU5aVw1NZ8rp+ZxyaRc0pI1UW8wimSCKACqur2uBi7uvoOZXQQUufuvzOzhHseu7HHsJ0ZHzex+4H6A8eNVKG6gbDtwmEeWbeDSyaN44CqV0ZCzl5X28cHuqqZjvL2tnne21vFcRTX/vmIPyUkJLJw0iiun5HHFlDxK8nR1MVhE7S4mM0sAvgd88Wzfw90fBx6HUBfTwEQW39o6Ovnq02tJTxnGP941R2U0ZEAV5Qzn8wsn8PmFE2ht76R8dxNvbann7W11PPpyqHOhYGQal5eGbqNdVDJKY19RFMkEUQMUdXtdGLSdlAHMAN4O/loYAywzsxvDOFYi5Pu/3c6W/Yd58ovzNVNaIip1WCKXl4YqzT7CdKqajvHu9np+t62BX31UyzPloQ6IC8ZmhhZJKs1lQXEOI1J0d/75EslB6iRCg9TXEPpyLwfudfeNp9n/beDrwSD1hcBT/H6Q+g2gVIPUkbV270Fu++H73D6vkO/ePjva4Ugc6+js4qOaZt7fERq/WL3nICc6uxiWaMwtyuaSYN0L3R117qIySO3uHWb2IPAaodtcn3D3jWb2KFDh7sv6OHajmS0hNKDdATzQV3KQc9fa3snXn1vPmMxU/vqG6dEOR+JcUmICc8dnM3d8Ng9cNZnjJzqp2NPE8soGVuxo5Advbuf7b2wnbVgiZcXZLCrJ5dLJo7hwXJa6RQeQJsoJEFr85/F3d/Lz+xZweWletMMR6VPzsXZW7mo8tVDStgOhZVgzUpNYOCl0dXFJySim5GeQoITRJ9Vikj5trm3hp7/byT0LipQcZEjIGv7xu6PqDreyYkcoYby3o+FU7aicEcksnJTDJZNCCUPFBvtHCSLOuTuPvLSBrLRhfGPxtGiHI3JW8jM+vgxr9cHQMqwrdjayckcjr3y0H4C8jJRTyeKSSaOYMGq4EkYflCDi3NK1NZTvPsh3bpvJyOHJ0Q5HZEAUZg/njrLh3FEWWoZ1b9PvE8b73dbtHpuVyiWTRrEwSBhFOcOjHPngogQRx46f6OS7v97K7MIs7phXdOYDRIYgM2PCqBFMGDWCuxeMD9btPnrq6uKdbfW8uDZ0F31RThqLJuWyaHIoYeRnxvet3koQcezJ93exv6WV7989RwN5EjfMjMn56UzOT+fzCyfg7mw7cIQVOxpYsbORVzfU8mxFaA7GpNwRXDwphwUTQ+VDCrPj6wpDCSJOHTx6gh++vYNrpuVzsWotSRwzM6aOyWDqmAy+eOlEOrucTftaWLGzgQ92NvHyh7U8vSqUMApGpjG/OJv5QcKYnJce039cKUHEqR+9u4OjbR1849MamBbpLjHBmFmYxczCLO6/ooTOLmfr/sOs2tXIqt1NLK9s5BfrQmMYWWnDKJuQTVlxDvOLs5lZmEVKUuwUHlSCiEOHjp3gP1bs4YZZ45gyOiPa4YgMaokJxvRxmUwfl8kXL52Iu7On8Rjlu5uo2H2Q8j1NvLGlDoDkpARmF2ZRVpzDguIcLhqfPaQXTlKCiENPvreboyc6ValV5CyYGcW5IyjOHcEdZaGbOxqOtLF6z0EqdjdRvvsgP3l3Jz98ewdmMHV0BmXF2cwvzqGsOIeCkWlRPoPwKUHEmcOt7Tz53i7+YPpopo7R1YPIQMhNT/nYxL3jJzpZW3UwdIWxu4mla2r4j5V7ARiXlXqqS6qsOIcpozMGbXkQJYg48x8r99LS2sGDV+vqQSRS0pITWVSSy6KSXCBUfHDL/sOhK4w9B1m58/dzMTJSk5g3IbjCmJDN7KKRpA4bHOMYShBxpK2jk39dvovLS3OZVTgy2uGIxI2kxARmFGQxoyDr1DhG9cHjlAddUhW7m3h761YAkhMTmFmYFeqWmpDDvAnZZI+IziRWJYg48sv1tTQcaeNLV8yJdigicc3MKMoZTlHOcG69qBAI3Xq+ek9o0Lti90GeWL6LH7+zE4DS/HTmTwxdYYTmY6SdlxIhShBxwt158r1dlOanc+lkzXsQGWyyRyRz7fTRXDt9NBAqwf9hdXNwldHEL9ft46kPQuMYozNTTq39XVaczbQxmREZx1CCiBMVew6ycV8Lf3/LDBUnExkCUoclsmBiaBY3cGo+xuo9oW6p8t2hSXwAMwoyefnPLx/wGJQg4sST7+0iK20Yt8wtiHYoInIWus/H+PwlxQDUHDpOxe4mOrsis66PEkQcqDl0nNc2HuBPL5vI8GT9JxeJFQUj0yiYE7k/+rSYaxx4+oO9uDufv2RCtEMRkSFECSLGtXd2saSiiiun5sddJUoROTdKEDHuzS111B1u454F46MdiogMMUoQMe6pD/YyJjOVq6ZqrWkR6R8liBhW1XSMd7fXc+f8IpIS9Z9aRPpH3xoxbEmwKtZd87WcqIj0nxJEjOro7OLZ8iqunJI3pMoLi8jgoQQRozQ4LSLnSgkiRj21ai+jM1O4elp+tEMRkSEqognCzBab2VYzqzSzb/ay/ctm9pGZrTOz5WY2PWgvNrPjQfs6M/tRJOOMNbXNx3lnWz13lmlwWkTOXsTqLphZIvAYcB1QDZSb2TJ339Rtt6fc/UfB/jcC3wMWB9t2uPucSMUXy15atw93TpURFhE5G5H883IBUOnuO939BPAMcFP3Hdy9pdvLEUBkKk7FEXdn6Zoa5o4fycTcEdEOR0SGsEgmiAKgqtvr6qDtY8zsATPbAXwX+Gq3TRPNbK2ZvWNmvdaxNbP7zazCzCrq6+sHMvYha3PtYbYeOMytqtoqIufojAnCzKaY2U/M7Ddm9ubJx0AF4O6PuXsJ8A3gr4PmWmC8u88FHgKeMrPMXo593N3L3L0sL08zhQGWrq1mWKJxw6xx0Q5FRIa4cMYgngN+BPwE6OzHe9cA3WdoFQZtp/MM8EMAd28D2oLnq4MrjClART8+P+50djkvrdvHlVPzo7aGrYjEjnASRIe7//As3rscKDWziYQSw93Avd13MLNSd98evPxDYHvQngc0uXunmU0CSoGdZxFDXHmvsoG6w21aFEhEBkQ4CeKXZvZnwFKCv+oB3L2pr4PcvcPMHgReAxKBJ9x9o5k9ClS4+zLgQTO7FmgHDgJfCA6/AnjUzNqBLuDLZ/o8gaVra8hITdLcBxEZEOEkiJNf2g93a3Ng0pkOdPdXgFd6tD3S7fnXTnPcC8ALYcQmgaNtHfx6w35unjuO1GGJ0Q5HRGLAGROEu088H4HIuXlt436Ot3dyy1zNfRCRgXHGBGFmw4CvEOr2AXgb+LG7t0cwLumnpWtrKMxOo2xCdrRDEZEYEc48iB8C84D/EzzmBW0ySNS1tPJeZQO3zC0gIcGiHY6IxIhwxiDmu/vsbq/fNLP1kQpI+u+ldfvocrhZdy+JyAAK5wqi08xKTr4Ibjvtz3wIibAX19YwuzCLkrz0aIciIjEknCuIh4G3zGwnYMAE4I8jGpWEbcv+FjbXtvA/Pjs92qGISIwJ5y6mN8ysFJgaNG0NZjrLILB0TQ1JCcZnZ6u0hogMrNMmCDO72t3fNLNbe2yabGa4+4sRjk3O4GRpjU9NyWNUekq0wxGRGNPXFcSngDeBz/ayzQEliChbubOR/S2t/PUNF0Q7FBGJQadNEO7+N8HTR919V/dtQX0libIX19SQkZLEtReMjnYoIhKDwrmLqbeSF88PdCDSP8dPdPLrDbV8euYYldYQkYjoawxiGnAhkNVjHCITSI10YNK332zaz9ETKq0hIpHT1xjEVOAGYCQfH4c4DPyXCMYkYXhxTQ0FI9O4eGJOtEMRkRjV1xjES8BLZnaJu684jzHJGdQdbuV32+v58qdKVFpDRCImnIlya83sAULdTae6ltz9TyIWlfTpl+tr6XK49SKV1hCRyAlnkPrnwBjgeuAdQkuHHo5kUNK3pWurmVmQxeT8jGiHIiIxLJwEMdnd/ztw1N3/jdDSoBdHNiw5ne0HDrOhpkWF+UQk4sJJECfXfThkZjOALEBrWkbJi2trSEwwblRpDRGJsHDGIB43s2zgvwPLgHTgkb4PkUjo7HJ+sbaGy0tzyctQaQ0RiaxwivX9NHj6DmGsQy2Rs3JnI7XNrfy/n1FpDRGJvL4myj3U14Hu/r2BD0f68sLqajJSk7huukpriEjk9XUFoVtkBpEjbR28umE/N88dp9IaInJe9DVR7m/PZyDSt1c/quV4eye3XaTSGiJyfpzxLiYzm2Jmb5jZhuD1LDP768iHJt29sKaa4lHDmTchO9qhiEicCOc2158A3yK43dXdPwTujmRQ8nHVB4+xcmcTt15UiJlKa4jI+RFOghju7qt6tHVEIhjp3dI1NQDcoslxInIehZMgGsyshNAqcpjZ7UBtOG9uZovNbKuZVZrZN3vZ/mUz+8jM1pnZcjOb3m3bt4LjtprZ9WGeT8xxd15cW8PFE3Moyhke7XBEJI6EM1HuAeBxYJqZ1QC7gD8600Fmlgg8BlwHVAPlZrbM3Td12+0pd/9RsP+NwPeAxUGiuJtQgcBxwG/NbIq7d4Z/arFhzd6D7Go4yleuLIl2KCISZ/pMEMGX/J+5+7VmNgJIcPdwC/UtACrdfWfwXs8ANwGnEoS7t3TbfwTBVUqw3zPu3gbsMrPK4P3iruz4s+VVDE9O5DMzx0Y7FBGJM30mCHfvNLPLgudH+/neBUBVt9fV9FLkLygl/hCQDFzd7diVPY79RAe8md0P3A8wfvz4foY3+DUfb+eX62u5ac440lPCudgTERk44YxBrDWzZWb2eTO79eRjoAJw98fcvQT4BtCv22fd/XF3L3P3sry8vIEKadD4xdoajrd3cu/FsZf8RGTwC+fP0lSgkd//dQ+hrqAXz3BcDVDU7XVh0HY6zwA/PMtjY46789QHe5lRkMmswpHRDkdE4lA4YxCN7v71s3jvcqDUzCYS+nK/G7i3x/uXuvv24OUfAiefLwOeMrPvERqkLgV63mob09bsPcjWA4f5X7fOjHYoIhKnwhmDuPRs3tjdO8zsQeA1IBF4wt03mtmjQIW7LwMeNLNrCU3COwh8ITh2o5ktITSg3QE8EG93MP3nB3tJT0nSug8iEjXhdDGtM7NlwHPAqYFqdz9TFxPu/grwSo+2R7o9/1ofx/498PdhxBdzDh07wcsf1nLHvEJGaHBaRKIkkmMQcpZeWFPDiY4uDU6LSFSFs2DQH5+PQCQkNDi9hzlFI7lwXFa0wxGROBZONddCM1tqZnXB4wUzU83pCFm1q4kd9Ud19SAiURfOPIgnCd1VNC54/DJokwj4zw/2kpGaxGdnaXBaRKIrnASR5+5PuntH8PgZEHuz0gaBpqMn+PWG/dw6t4C0ZK0aJyLRFU6CaDSzz5lZYvD4HKFBaxlgz6+u4kRnF/dePCHaoYiIhJUg/gS4E9hPqMz37YAGrgdYV1do5nTZhGymjtFy4CISfeHcxbQHuPE8xBLXVuxsZHfjMb56TWm0QxERAfq4gjCzfzCzL/XS/iUz+3Zkw4o/T6/aS1baMJX1FpFBo68upqsJLRTU00+AGyITTnw6dOwEv9l4gJvnjCN1mAanRWRw6CtBpLi792x09y7AIhdS/Hlp3T5OdHZx5/yiM+8sInKe9JUgjpvZJzrEg7bjkQsp/iypqOLCcZmaOS0ig0pfCeIR4FUz+6KZzQwefwz8KtgmA2BDTTMb97VwZ5muHkRkcDntXUzu/qqZ3Qw8DPx50LwBuM3dPzoPscWF5yqqSE5K4KY5mjktIoPLmdaD2ECwRoMMvNb2Tn6xbh/XXziGkcOTox2OiMjHhDNRTiLk9U0HaD7ezp1lqn0oIoOPEkQULamoomBkGpeW5EY7FBGRTwin3Pcnlhw922VI5feqDx5jeWUDt88rJCFBdw2LyOATzhXEP4fZJv3wwuoa3OH2eepeEpHB6bSD1GZ2CbAIyDOzh7ptygQ03fccdHU5z62u4tLJoyjKGR7tcEREetXXFUQykE4oiWR0e7QQqugqZ2nlzkaqDx7X3AcRGdT6mgfxDvCOmf0sqOiKmSUA6e7ecr4CjEXPVlSRmZrE9ReOiXYoIiKnFc4YxP8ys0wzG0FootwmM3s4wnHFrOZj7by6YT83zSlQYT4RGdTCSRDTgyuGm4FXgYnA5yMZVCxb9uE+TnR0qXtJRAa9cBLEMDMbRihBLHP3duATVV4lPM9VVDFtTAYzCjKjHYqISJ/CSRA/BnYDI4B3zWwCoYFq6afNtS18WN3MXfOLMNPcBxEZ3M6YINz9B+5e4O6f8ZA9wFXhvLmZLTazrWZWaWbf7GX7Q2a2ycw+NLM3guRzclunma0LHsv6dVaD1JKKKpITE7h5TkG0QxEROaNwZlKPNrN/NbNXg9fTCaOAn5klAo8BnwamA/cEx3a3Fihz91nA88B3u2077u5zgseQXxO7raOTX6yt4brpo8keocJ8IjL4hdPF9DPgNeBkPeptwH8N47gFQKW773T3E8AzwE3dd3D3t9z9WPByJRCz04rf2FzHwWPt3KHCfCIyRJw2QZjZyTkSue6+BOgCcPcOoDOM9y4Aqrq9rg7aTuc+QndJnZRqZhVmtjJYl6K3GO8P9qmor68PI6Toeba8irFZqVxemhftUEREwtLXFcSq4N+jZjaK4M4lM1sINA9kEGb2OaAM+IduzRPcvQy4F/gnMyvpeZy7P+7uZe5elpc3eL949x06zrvb67l9XiGJKswnIkNEXwsGnfwmewhYBpSY2XtAHuGV2qgBut/sXxi0ffxDzK4F/gr4lLu3nWx395rg351m9jYwF9gRxucOOi+uqVZhPhEZcvpKEN2L9C0FXiGUNNqAa4EPz/De5UCpmU0klBjuJnQ1cIqZzSV0G+1id6/r1p4NHHP3NjPLBS7l4wPYQ0ZXl7OkopqFk3KYMGpEtMMREQlbXwkikVCxvp59ImGVH3X3DjN7kNAAdyLwhLtvNLNHgQp3X0aoSykdeC6YF7A3uGPpAuDHZtZFqBvs2+6+qR/nNWis2t3E3qZj/LfrSqMdiohIv/SVIGrd/dFzeXN3f4XQlUf3tke6Pb/2NMe9D8w8l88eLJaUV5GRksTiC8dGOxQRkX7pa5Bao6nnqKW1nVc21PLZOeNIS1ZhPhEZWvpKENectyhi1Mvra2lt7+IuFeYTkSHotAnC3ZvOZyCxaElFFVNHZzCrMCvaoYiI9Fs4M6nlLGw7cJh1VYe4o6xQhflEZEhSgoiQJeVVDEs0bpmrwnwiMjQpQUTAiY4ulq6t4doLRjMqPSXa4YiInBUliAh4c0sdjUdPaNU4ERnSlCAiYElFFaMzU7i8NDfaoYiInDUliAF2oKWVt7fWcdtFhSQl6scrIkOXvsEG2Atrquly1L0kIkOeEsQAcneeq6hmwcQcinNVmE9EhjYliAFUvvsguxqO6upBRGKCEsQAWlJRRXpKEp+ZOSbaoYiInDMliAFypK2DX31Yy2dnj2V4cl9FckVEhgYliAHyqw/3cby9kzvUvSQiMUIJYoAsqahmcn46c4tGRjsUEZEBoQQxACrrDrN6z0HuVGE+EYkhShAD4LmKapISjFvmFkY7FBGRAaMEcY7aO7t4YU0NV0/LJy9DhflEJHYoQZyjt7bU0XCkTXMfRCTmKEGcoyUVVeRnpHDl1LxohyIiMqCUIM7BgZZW3tpaz23zVJhPRGKPvtXOwfOrq+nscnUviUhMUoI4S6HCfFUsmJjDRBXmE5EYpARxlj7Y1cTuxmPcPV9XDyISm5QgztKS8ioyUpL49Iyx0Q5FRCQiIpogzGyxmW01s0oz+2Yv2x8ys01m9qGZvWFmE7pt+4KZbQ8eX4hknP3VfLydVzbUcuOccaQlJ0Y7HBGRiIhYgjCzROAx4NPAdOAeM5veY7e1QJm7zwKeB74bHJsD/A1wMbAA+Bszy45UrP21bP0+Wtu7uEvdSyISwyJ5BbEAqHT3ne5+AngGuKn7Du7+lrsfC16uBE7WqrgeeN3dm9z9IPA6sDiCsfbLkvIqpo3JYGZBVrRDERGJmEgmiAKgqtvr6qDtdO4DXu3PsWZ2v5lVmFlFfX39OYYbnk37Wvioppm75hepMJ+IxLRBMUhtZp8DyoB/6M9x7v64u5e5e1le3vmZybykoorkpARumdtXrhMRGfoimSBqgO6d9IVB28eY2bXAXwE3untbf44931rbO1m6tobrLxzDyOHJ0Q5HRCSiIpkgyoFSM5toZsnA3cCy7juY2Vzgx4SSQ123Ta8Bf2Bm2cHg9B8EbVH12sb9NB9v5y7NnBaROBCxxZPdvcPMHiT0xZ4IPOHuG83sUaDC3ZcR6lJKB54L+vP3uvuN7t5kZn9HKMkAPOruTZGKNVzPlldRlJPGopJR0Q5FRCTiIpYgANz9FeCVHm2PdHt+bR/HPgE8Ebno+mdP41He39HIX1w3hYQEDU6LSOwbFIPUQ8GSiioSDG4v06pxIhIflCDC0NHZxfOrq7lyaj5js9KiHY6IyHmhBBGGd7bVc6ClTTOnRSSuKEGE4ZnyKnLTU7h6Wn60QxEROW+UIM6grqWVN7fUcfu8QoZp1TgRiSP6xjuD59eEVo1T95KIxBsliD64O8+WV3GxVo0TkTikBNGHlTub2NN4jLsX6OpBROKPEkQfni3fS0aqVo0TkfikBHEazcfaeWXDfm6eU0DqMK0aJyLxRwniNH6xroYTHVo1TkTilxLEaTxbXsWF4zKZoVXjRCROKUH0YkNNM5tqW3T1ICJxTQmiFydXjbtptlaNE5H4pQTRQ2t7J79YW8PiC8eQNXxYtMMREYkaJYgeXtu4n5bWDnUviUjcU4LoYUlFFYXZaVwySavGiUh8U4LopqrpGO9VNnLHvCKtGicicU8JopvnVldjWjVORARQgjils8t5vqKKyybnUjBSq8aJiChBBN7dXs++5lbuLNPgtIgIKEGc8vMVe8hNT+H6C8dEOxQRkUFBCQLY03iUt7bWce/F40lO0o9ERASUIIDQ1UOiGX908fhohyIiMmjEfYI4dqKDJRVVLJ4xhtGZqdEOR0Rk0Ij7BHG4tYPLp+TxxUXF0Q5FRGRQiWiCMLPFZrbVzCrN7Ju9bL/CzNaYWYeZ3d5jW6eZrQseyyIV4+jMVB679yLKinMi9REiIkNSUqTe2MwSgceA64BqoNzMlrn7pm677QW+CHy9l7c47u5zIhWfiIj0LWIJAlgAVLr7TgAzewa4CTiVINx9d7CtK4JxiIjIWYhkF1MBUNXtdXXQFq5UM6sws5VmdnNvO5jZ/cE+FfX19ecQqoiI9DSYB6knuHsZcC/wT2ZW0nMHd3/c3cvcvSwvL+/8RygiEsMimSBqgO51KwqDtrC4e03w707gbWDuQAYnIiJ9i2SCKAdKzWyimSUDdwNh3Y1kZtlmlhI8zwUupdvYhYiIRF7EEoS7dwAPAq8Bm4El7r7RzB41sxsBzGy+mVUDdwA/NrONweEXABVmth54C/h2j7ufREQkwszdox3DgCgrK/OKiopohyEiMqSY2epgvPeT22IlQZhZPbDnHN4iF2gYoHCGCp1zfNA5x4ezPecJ7t7rXT4xkyDOlZlVnC6Lxiqdc3zQOceHSJzzYL7NVUREokgJQkREeqUE8XuPRzuAKNA5xwedc3wY8HPWGISIiPRKVxAiItIrJQgREelV3CeIMy1qNFSZ2RNmVmdmG7q15ZjZ62a2Pfg3O2g3M/tB8DP40Mwuil7kZ8/MiszsLTPbZGYbzexrQXvMnreZpZrZKjNbH5zz3wbtE83sg+Dcng3K3WBmKcHrymB7cVRP4ByYWaKZrTWzl4PXMX3OZrbbzD4KFlGrCNoi+rsd1wmi26JGnwamA/eY2fToRjVgfgYs7tH2TeANdy8F3gheQ+j8S4PH/cAPz1OMA60D+At3nw4sBB4I/nvG8nm3AVe7+2xgDrDYzBYC3wH+0d0nAweB+4L97wMOBu3/GOw3VH2NUBmfk+LhnK9y9znd5jtE9nfb3eP2AVwCvNbt9beAb0U7rgE8v2JgQ7fXW4GxwfOxwNbg+Y+Be3rbbyg/gJcIrWgYF+cNDAfWABcTmlGbFLSf+j0nVBvtkuB5UrCfRTv2szjXwuAL8WrgZcDi4Jx3A7k92iL6ux3XVxCc+6JGQ81od68Nnu8HRgfPY+7nEHQjzAU+IMbPO+hqWQfUAa8DO4BDHiqYCR8/r1PnHGxvBkad14AHxj8BfwmcXI1yFLF/zg78xsxWm9n9QVtEf7cjueSoDGLu7mYWk/c4m1k68ALwX929xcxObYvF83b3TmCOmY0ElgLTohtRZJnZDUCdu682syujHM75dJm715hZPvC6mW3pvjESv9vxfgVxTosaDUEHzGwsQPBvXdAeMz8HMxtGKDn8p7u/GDTH/HkDuPshQuXxLwFGmtnJPwC7n9epcw62ZwGN5zfSc3YpcKOZ7QaeIdTN9H1i+5zx3y+iVkfoD4EFRPh3O94TxFkvajRELQO+EDz/AqE++pPt/09w58NCoLnbZeuQYaFLhX8FNrv797ptitnzNrO84MoBM0sjNOaymVCiuD3Yrec5n/xZ3A686UEn9VDh7t9y90J3Lyb0/+yb7v5HxPA5m9kIM8s4+Rz4A2ADkf7djvbAS7QfwGeAbYT6bf8q2vEM4Hk9DdQC7YT6H+8j1O/6BrAd+C2QE+xrhO7m2gF8BJRFO/6zPOfLCPXTfgisCx6fieXzBmYBa4Nz3gA8ErRPAlYBlcBzQErQnhq8rgy2T4r2OZzj+V8JvBzr5xyc2/rgsfHkd1Wkf7dVakNERHoV711MIiJyGkoQIiLSKyUIERHplRKEiIj0SglCRER6pQQh0g9m1hlU0zz5GLAKwGZWbN2q74pEm0ptiPTPcXefE+0gRM4HXUGIDICgVv93g3r9q8xsctBebGZvBjX53zCz8UH7aDNbGqzjsN7MFgVvlWhmPwnWdvhNMDtaJCqUIET6J61HF9Nd3bY1u/tM4F8IVRsF+Gfg39x9FvCfwA+C9h8A73hoHYeLCM2OhVD9/sfc/ULgEHBbRM9GpA+aSS3SD2Z2xN3Te2nfTWjhnp1BwcD97j7KzBoI1eFvD9pr3T3XzOqBQndv6/YexcDrHlr8BTP7BjDM3f+/83BqIp+gKwiRgeOned4fbd2ed6JxQokiJQiRgXNXt39XBM/fJ1RxFOCPgN8Fz98AvgKnFvzJOl9BioRLf52I9E9asHrbSb9295O3umab2YeErgLuCdr+HHjSzB4G6oE/Dtq/BjxuZvcRulL4CqHquyKDhsYgRAZAMAZR5u4N0Y5FZKCoi0lERHqlKwgREemVriBERKRXShAiItIrJQgREemVEoSIiPRKCUJERHr1fwGR3A0LY2buWQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [x[0] for x in trcorr]\n",
    "# print(trcorr)\n",
    "plt.plot(x[0:], label='Ours (Current)')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Test Correlation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c8056e44361b3025550c65bc5010df772222063d102b1bd819b2bb25510c77a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
